\documentclass[oneside]{book}
\usepackage{color}
\definecolor{bg}{rgb}{0.95,0.95,0.95}
\definecolor{emphcolor}{rgb}{0.5,0.0,0.0}
\newcommand{\empha}{\bf\color{emphcolor}}
\usepackage{parskip}
\usepackage[newfloat=true]{minted}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{imakeidx}
\usepackage{tikz}
\usetikzlibrary{shapes,shadows,arrows}
\makeindex[title=General Index]
\makeindex[name=codeindex,title=Code Index]
\usemintedstyle{friendly}
\setminted{bgcolor=bg,xleftmargin=20pt}
\usepackage{hyperref}
\hypersetup{pdftex,colorlinks=true,allcolors=blue}
\newcommand*{\fullref}[1]{\hyperref[{#1}]{\autoref*{#1} \nameref*{#1}}}
\usepackage{hypcap}
\usepackage{caption}
\DeclareMathOperator{\quot}{div}
\DeclareMathOperator{\rmd}{rmd}
\title{Programming with Coroutines}
\author{John Skaller}
\begin{document}
\maketitle
\tableofcontents
\chapter{Introduction}
Coroutines are not a new concept, however they have been ignored for
far too long. They solve many programming problems in a natural way and
any decent language today should provide a mix of coroutines and procedural
and functional subroutines, as well as explicit continuation passing.

Alas, since no such system exists to my knowledge I have had to create
one to experiment with: Felix will be used in this document simply
because there isn't anything else!

\section{What is a coroutine?}
A {\em coroutine} is basically a procedure which can be {\em spawned} to begin
a {\em fibre} of control which can be {\em suspended} and {\em resumed} under program
control at specific points. Coroutines communicate with each other
using {\em synchronous channels} to read and write data from and to other
coroutines. Read and write operations are synchronisation points,
which are points where a fibre may be suspended or resumed.

Although fibres look like threads, there is a vital distinction: multiple
fibres make up a single thread, and within that only one fibre is ever
executing. Fibration is a technique used to structure sequential programs,
there is no concurrency involved.

The most significant picture of the advantages of coroutines is thus: in a subroutine
based language there is a single machine stack. By machine stack, I mean that
there is an important {\em implicit} coupling of control flow and local variables.
In the abstract, a subroutine call passes a continuation of the caller to 
the callee which is saved along with local variables the callee allocates,
so that the local variables can be discarded when the final result is
calculated, and then passed to the continuation. This technique may be
called {\em structured programming}. With coroutines, the picture is simple:
each fibre of control has its own stack. Communication via channels exchanges data
and control between stacks.

Coroutines therefore leverage control and data coupling in a much more
powerful and flexible manner than mere functions, reducing the need for
state to be preserved on the heap, thereby making it easier to construct
and reason about programs.

For complex applications, the heap is always required.


\section{A Simple Example}
The best way to understand coroutines and fibration is to have a look
at a simple example. 

\subsection{The Producer}
First, we make a coroutine procedure which writes the integers
from 0 up to but excluding 10 down a channel.

\begin{listing}
\begin{minted}{felix}
proc producer (out: %>int) () {
  for i in 0..<10 
    perform write (out, i);
}
\end{minted}
\caption{Simple source}
\label{lst:Simple source}
\end{listing}
Notice that as well as passing the output channel argument \verb%out%,
there is an extra unit argument \verb%()%. This procedure terminates
after it has written 10 integers. The type of variable \verb%out% is
denoted \verb$%>int$ which is actually short hand for \verb%ochannel[int]%,
which is an output channel on which values of type \verb%int% may
be written.

\subsection{The Transducer}
Next, we make a device which repeatedly reads an integer, squares it,
and writes the result. It is an infinite loop, this coroutine never
terminates of its own volition. This is typical of coroutines.

\begin{listing}
\begin{minted}{felix}
proc transducer (inp: %<int, out: %>int) () {
  while true do
    var x = read inp;
    var y = x * x;
    write (out, y);
  done
}
\end{minted}
\caption{A simple transducer}
\label{lst:A simple transducer}
\end{listing}

Here, the type of variable \verb%inp% is
denoted \verb$%<int$ which is actually short hand for \verb%ischannel[int]%,
which is an input channel from which values of type \verb%int% may
be read.

\subsection{The Consumer}
Now we need a coroutine to print the results:

\begin{listing}
\begin{minted}{felix}
proc consumer (inp: %<int) () {
  while true do
    var y = read inp;
    println y;
  done
}
\end{minted}
\caption{A simple sink}
\label{lst: A simple sink}
\end{listing}

Each of these components is a coroutine because it is a procedure
which may perform, directly or indirectly, I/O on one or more synchronous
channels.

\subsection{Purity}
The first two coroutines are {\em pure} because they depend only on their
arguments, and interact with the outside world entirely through 
synchronous channels. They do not modify variables in their environment,
and they do not depend on variables in their environment. The consumer,
however, has a side effect, namely printing values to standard output.

Purity is an important property which provides modularity and encapsulation and allows
one to reason locally. This is a vital information hiding property which is also
possessed by pure functions, where it is known as {\em functional abstraction}. 

They key idea of functional abstraction is that an approximation of the
function semantics is represented by the function type. For example
the functions \verb%modulus% and \verb%argument%

\begin{minted}{felix}
fun modulus (z:dcomplex) : double => sqrt (z.x^2 + z.y^2);
fun argument (z:dcomplex) : double => arctan2 (z.y, z.x);
\end{minted}

both have type \verb% dcomplex -> double%, so the type is only an approximation
which forgets some details of the function, which is the usual meaning
of abstract. Never-the-less the type is useful to allow the type checker
to prevent calling these functions on an integer, but more importantly
it allows for higher order functions:

\begin{minted}{felix}
fun map (x:list[dcomplex]) (f:dcomplex->double) =>
  match x with
  | Empty => Empty[double]
  | Cons (head, tail) => Cons (f head, map f tail)
  endmatch
;
\end{minted}

This function will take a list of \verb%dcomplex% and apply either
\verb%modulus% or \verb%argument% or any other function with
the type \verb%dcomplex->double% to the list to produce a list
of \verb%double% safely: the point is that this map function
does not need to know the full semantics of the argument to which
the parameter \verb%f% is bound, only that it has the correct type.

For coroutines,
we would call this cofunctional abstraction, however there's a problem: functions are
abstracted to function types. However the behaviour of a coroutines depend not just
on the data type of the channels, but also on the order in which operations
are performed on these channels, and that information should be approximated
and symbolised by a {\em control type}. Alas, 

\noindent {\bf we do not have a suitable type system.}

\subsection{Synchronous Channel Construction}
Now, let us see how we can use these coroutines in the obviously
intended way! First we have to make some channels to connect
the devices:

\begin{listing}
\begin{minted}{felix}
proc doit () {
  var ich1, och1 = mk_ioschannel_pair[int]();
  var ich2, och2 = mk_ioschannel_pair[int]();
\end{minted}
\caption{Construct channels}
\label{lst:construct channels}
\end{listing}

Note, we have only created two channels here! But we have
made two interfaces to the same channel, the first input,
and the second output.

\subsection{Connecting Devices with Channels}
Now we can connect the devices to the channels:

\begin{listing}
\begin{minted}{felix}
  var p = producer och1;
  var t = transducer (ich1, och2);
  var c = consumer (ich2);
\end{minted}
\caption{Bind Channel Arguments}
\label{lst:bind channel arguments}
\end{listing}

We have created procedure closures which bind the channel arguments
to the procedures so that now the three closures all have the type
\verb%1->0%, where 1 is also named as \verb%unit% and 0 is named as \verb%void%,
which is required for the next step.

\subsection{Spawning Fibres}
Now we spawn active fibres from the coroutine closures:

\begin{listing}
\begin{minted}{felix}
  spawn_fthread p;
  spawn_fthread t;
  spawn_fthread c;
}
doit();
\end{minted}
\caption{Spawn Fibres}
\label{lst:spawn fibres}
\end{listing}

What we have done here is spawn three fibres which then communicate
via the connected channels. The configuration in a series is called
a {\em pipeline} and corresponds directly to functional composition.

\subsection{Termination}
Now you may wonder, how does it all end? What happens is that
when the producer terminates by a procedural return which is
called {\em suicide}. The transducer tries to read a value
which is never going to come. The transducer is said to {\em starve}.
The consumer also waits forever for a value from the transducer
which is never going to come, because the transducer is starving,
so the consumer also starves.

It is also possible for a coroutine to {\em block}. This happens when
it tries to write a value which will never be read. Lets modify
our example to see: an infinite production stream:

\begin{listing}
\begin{minted}{felix}
proc producer (out: %>int) () {
  var i = 0;
  while true do
    write (out, i);
    ++i;
  done
}
\end{minted}
\caption{Infinite Source}
\label{lst:infinite source}
\end{listing}

but a limited sample of data are printed:

\begin{listing}
\begin{minted}{felix}
proc consumer (inp: %<int) () {
  for i in 0..<10 do
    var y = read inp;
    println y;
  done
}
\end{minted}
\caption{Finite sink}
\label{lst:finite sink}
\end{listing}

Now, the transducer blocks when the consumer terminates, and thus
the producer blocks because the transducer has.

The astute programmer will have a number of questions!
When a pre-emptive thread starves or blocks, it is a serious
problem. Have we made a mistake with our fibres?

Here, you start on your journey to a major paradigm shift!
Blockage and starvation are not an error with coroutines,
its normal, expected, and desirable! This is, in fact,
the main way that we organise termination!

Before I can explain this, however, I have to back step a bit!

\section{Garbage Collection and Reachability}
Felix runs a garbage collector similar to most functional programming
languages. What a collector does is maintain a specified set of root
objects, and finds all the objects to which there is a pointer
in one of the roots. It then expands the set to include all the objects
for which there is a pointer in one of those objects, and so on.
If an object A has a pointer to an object B, we say B is directly
reachable from A. If B then has a pointer to C, then C is said to be
reachable from A, by first visiting B. The complete set of objects
reachable from the designated roots is the transitive closure of the
reachability relation. The other objects which are not reachable
are garbage and are deleted. There's no way to refer to such an object,
since there are no pointers to it in the roots, or any object reachable
from the root.

\begin{figure}[h]
\begin{center}
\tikzstyle{cell} = [rectangle,minimum width=2cm,minimum height=1cm,text centered,draw=black]
\tikzstyle{arrow} = [thick,->,>-stealth]
\begin{tikzpicture}[node distance=3cm]
\node(A)[cell]{A};
\node(B)[cell,right of=A]{B};
\node(C)[cell,right of=B]{C};
\draw[arrow](A) -- (B);
\draw[arrow](B) -- (C);
\end{tikzpicture}
\caption{Reachability}
\end{center}
\end{figure}

Now, the secret of Felix coroutines is as follows: when you spawn
a coroutine, the resulting fibre is reachable by the system,
but it is {\em not} reachable from the caller. There is no "thread-id"
returned when a coroutine is spawned, if you want to communicate
with it you have to use a channel. The coroutine is named, the 
fibre spawned, however, is {\em anonymous}.

Now what happens is very simple but you will have to concentrate
to get it! Coroutines passed channels can reach the channel.
Any procedure which stores the channel can reach the channel.
But the channel is an object and initially it can't reach anything.
However when a coroutine performs I/O on the channel it can be
suspended. If a read is done, and there is not yet a matching write,
the fibre is suspended by adding it to the channel. Now the channel
can reach the fibre. At the same time the system {\em forgets} the
fibre. The system keeps a list of active fibres, but a suspended
fibre is not active so it is forgotten.

A read operation is matched by a write, and a write operation
is matched by a read. When a matching I/O operation is performed
on a channel it means that the other operation that matches it
has already been performed by another fibre. In this case,
the channel forgets that fibre, and {\em both} that fibre and the
one performing the matching operation become active and reachable
by the system.

A more detailed explanation follows. A formal definition of the
precise execution semantics is given in \fullref{Coroutine Semantics}.

\section{Execution Model}
When Felix starts your program, the machine stack is reachable,
and so any object with a pointer on the machine stack is reachable.
In addition, your initial mainline code is implicitly a coroutine,
which is spawned automatically creating a fibre object
which contains a pointer to the fibre's initial continuation.
The fibre is running, so it is also reachable.

All your top level variables are stored in an object called
the {\em thread frame}. Continuation objects contain a pointer
to the thread frame so that the procedure can access the global
variables. A continuation object is also known as the procedure
{\em activation record} or {\em data frame}, or, historically,
its {\em stack frame}. As well as a pointer to the thread
frame, a continuation object also contains a pointer to the
most recent activation record of its ancestors, in fact the
thread frame may be consider a universal ancestor.

Vitally, continuation objects also contain a value known as
the program counter. This value is the current location at which
the continuation is executing, it always points into the code
of the procedure the frame represents. When a subroutine is
called, the program counter is set to the statement after the
subroutine call, a new continuation is created for the subroutine,
its program counter is set to the first statement, and a back pointer
to the caller continuation is stored. The back pointer, together with
the program counter of the caller, are together known as the subroutine
{\em return address}. It represents the continuation which the
subroutine resumes when the subroutine itself is complete.

Then the current continuation of the fibre is 
changed to the new continuation.

\begin{listing}
\begin{minted}{C++}
#if FLX_CGOTO
  #define FLX_LOCAL_LABEL_VARIABLE_TYPE void*
  #define FLX_PC_DECL void *pc;
#else
  #define FLX_PC_DECL int pc;
  #define FLX_LOCAL_LABEL_VARIABLE_TYPE int
#endif

\end{minted}
\caption{Code Address}
\label{lst:code address}
\end{listing}

\begin{listing}
\begin{minted}{C++}
struct con_t 
{
  FLX_PC_DECL               // interior program counter
  struct _uctor_ *p_svc;    // service request

  virtual con_t *resume()=0;// computation step
  con_t * _caller;          // return address
};
\end{minted}
\caption{Continuation base}
\label{lst:continuation base}
\end{listing}

\begin{listing}
\begin{minted}{C++}
struct fthread_t 
{
  con_t *cc;                // current continuation
};
\caption{Fibre}
\label{lst:fibre}
\end{minted}
\end{listing}

\begin{listing}
\begin{minted}{C++}
struct slist_node_t {
  slist_node_t *next;
  fthread_t *data;
};

struct slist_t {
  gc::generic::gc_profile_t *gcp; // garbage collector
  struct slist_node_t *head;
};

struct schannel_t
{
  slist_t *waiting_to_read;  // fthreads waiting for a writer
  slist_t *waiting_to_write; // fthreads waiting for a reader
};
\end{minted}
\caption{Synchronous Channel}
\label{lst:synchronous channel}
\end{listing}

When a return statement is executed, the backpointer to the
caller is stored into the fibre object, and execution continues
with the caller at the statement after the subroutine call.

Thus, the continuations form a singly linked list which operates
like a stack. The continuation objects are heap allocated and
the data structure is known as a {\em spaghetti stack}.
In principle, a continuation also has a pointer to the most recent
activation record of its parent, which has a pointer to its 
parent, until the list terminates with the thread frame,
so there are {\bf two} interleaved lists here: one representing
the call chain, and one representing the static nesting structure:
that is what make it a spaghetti stack. In Felix, pointers to all
the ancestors are stored in the continuation object to improve
access time to ancestoral variables, at the cost of passing them
all to each child (however the optimiser does lots of magic).

Each of the frame pointers mentioned is known to the garbage collector
and so a single reachable running procedure defines a transitive
closure of reachable objects. Note that in addition, any variable
containing a Felix pointer obtained from a manual heap allocation
ensures the heap object is reachable if the variable is in a 
reachable frame. In addition, any reachable pointer which points
anywhere into an object ensures the object is reachable.
If the pointer is not to the first byte, it is called
an {\em interior pointer}. Note that in Felix a pointer
"one past the end" of an object does not make the object
reachable!

Now all this explains, technically, something easy to state
loosely: if you can access an object it is reachable.
In addition if the {\em system} can access the object it
is reachable.

Now what I have described so far does not explain fibres.
The currently running fibre, and all those deemed active
are reachable by the system. When the currently running fibre
performs an unmatched synchronous channel I/O operation,
either a read or a write, it is added to the channel's
list of suspended fibres and is removed from the set of
fibre the system can reach directly. So the fibre can now
only be reached from the channel. So it will be garbage
unless another active fibre can reach the channel.
After all since the I/O operation is unmatched, if another
fibre can't see the channel, there is no fibre that
can satisfy the I/O request.

When a fibre is suspeneded by a read or write operation,
the program counter of its current continuation is set
to the statement after the I/O operation. If the operation
is later matched, the address of the data being transmitted
is transfered from the writer to the reader, and the two
fibres both made active so that they will continue
at the statement after the I/O operation.

What is vital to realise now is that each fibre has its
own spaghetti stack. So when control is exchanged
from one fibre to another:

\noindent {\bf control exchange is effected by stack swapping}

Of course, we mean the heap allocated spaghetti stacks.
You can swap machine stacks too: this is done by the host
operating system scheduler and the entities being context
switched are known as threads. The swaps are premptive,
and several stacks can be running at once if you have a 
multi-core CPU. Pre-emptive threads are much harder to use
than fibres, and the context switches are much more
expensive. They are greatly overused in many programs
for purpose of obtaining control inversion because
the host language is deficient and does not support
coroutines. This deficiency is shared by almost all
production and research programming systems!

\begin{figure}
\tikzstyle{cell} = [rectangle,minimum width=2cm,minimum height=1cm,text centered,draw=black]
\tikzstyle{blank} = [rectangle,minimum width=2cm,minimum height=1cm,text centered]
\tikzstyle{arrow} = [thick,->,>-stealth]
\begin{tikzpicture}[node distance=3cm]
\node(sys)[cell]{System};
\node(sys1)[blank,below of=sys]{};
\node(sys2)[blank,below of=sys1]{};
\node(sys3)[blank,below of=sys2]{};
\node(sys4)[blank,below of=sys3]{};
\node(prog)[cell,right of=sys1]{Fibre 0};
\node(doit)[cell,right of=prog]{doit};
\node(main)[cell,right of=doit]{Mainline};
\node(prod)[cell,right of=sys2]{Fibre 1};
\node(prod1)[cell,right of=prod]{producer};
\node(sys3a)[blank,right of=sys3]{};
\node(sys3b)[blank,right of=sys3a]{};
\node(chan)[cell,right of=sys3b]{schannel};
\node(cons)[cell,right of=sys4]{Fibre 2};
\node(cons1)[cell,right of=cons]{consumer};
\draw[arrow](sys) -- (prog);
\draw[arrow](sys) -- (prod);
\draw[arrow](sys) -- (cons);
\draw[arrow](prog) -- (doit);
\draw[arrow](doit) -- (main);
\draw[arrow](doit) -- (chan);
\draw[arrow](doit) -- (chan);
\draw[arrow](prod) -- (prod1);
\draw[arrow](cons) -- (cons1);
\draw[arrow](prod1) -- (chan);
\draw[arrow](cons1) -- (chan);
\end{tikzpicture}
\caption{Reachability: After Spawning}
\end{figure}


\begin{figure}
\tikzstyle{ucell} = [rectangle,minimum width=2cm,minimum height=1cm,text centered,draw=black!20]
\tikzstyle{cell} = [rectangle,minimum width=2cm,minimum height=1cm,text centered,draw=black]
\tikzstyle{blank} = [rectangle,minimum width=2cm,minimum height=1cm,text centered]
\tikzstyle{arrow} = [thick,->,>-stealth]
\tikzstyle{uarrow} = [thick,->,>-stealth,draw=black!20]
\begin{tikzpicture}[node distance=3cm]
\node(sys)[cell]{System};
\node(sys1)[blank,below of=sys]{};
\node(sys2)[blank,below of=sys1]{};
\node(sys3)[blank,below of=sys2]{};
\node(sys4)[blank,below of=sys3]{};
\node(prog)[ucell,right of=sys1]{Fibre 0};
\node(doit)[ucell,right of=prog]{doit};
\node(main)[ucell,right of=doit]{Mainline};
\node(prod)[cell,right of=sys2]{Fibre 1};
\node(prod1)[cell,right of=prod]{producer};
\node(sys3a)[blank,right of=sys3]{};
\node(sys3b)[blank,right of=sys3a]{};
\node(chan)[cell,right of=sys3b]{schannel};
\node(cons)[cell,right of=sys4]{Fibre 2};
\node(cons1)[cell,right of=cons]{consumer};
\draw[arrow](chan) -- (prod);
\draw[arrow](sys) -- (cons);
\draw[uarrow](doit) -- (chan);
\draw[arrow](prod) -- (prod1);
\draw[arrow](cons) -- (cons1);
\draw[arrow](prod1) -- (chan);
\draw[arrow](cons1) -- (chan);
\end{tikzpicture}
\caption{Reachability: Mainline completed, after Write, before Read}
\end{figure}


\begin{figure}
\tikzstyle{ucell} = [rectangle,minimum width=2cm,minimum height=1cm,text centered,draw=black!20]
\tikzstyle{cell} = [rectangle,minimum width=2cm,minimum height=1cm,text centered,draw=black]
\tikzstyle{blank} = [rectangle,minimum width=2cm,minimum height=1cm,text centered]
\tikzstyle{arrow} = [thick,->,>-stealth]
\tikzstyle{uarrow} = [thick,->,>-stealth,draw=black!20]
\begin{tikzpicture}[node distance=3cm]
\node(sys)[cell]{System};
\node(sys1)[blank,below of=sys]{};
\node(sys2)[blank,below of=sys1]{};
\node(sys3)[blank,below of=sys2]{};
\node(sys4)[blank,below of=sys3]{};
\node(prog)[ucell,right of=sys1]{Fibre 0};
\node(doit)[ucell,right of=prog]{doit};
\node(main)[ucell,right of=doit]{Mainline};
\node(prod)[ucell,right of=sys2]{Fibre 1};
\node(prod1)[ucell,right of=prod]{producer};
\node(sys3a)[blank,right of=sys3]{};
\node(sys3b)[blank,right of=sys3a]{};
\node(chan)[ucell,right of=sys3b]{schannel};
\node(cons)[ucell,right of=sys4]{Fibre 2};
\node(cons1)[ucell,right of=cons]{consumer};
\draw[uarrow](chan) -- (cons);
\draw[uarrow](doit) -- (chan);
\draw[uarrow](cons) -- (cons1);
\draw[uarrow](prod1) -- (chan);
\draw[uarrow](cons1) -- (chan);
\end{tikzpicture}
\caption{Reachability: Producer completed, Consumer starved, Program finished}
\end{figure}




\section{Indeterminacy}
When fibres synchronise with matching I/O operations, both become
active but only one actually starts executing. Which one is 
{\em indeterminate}. Felix always runs the reader first, but
in the abstract semantics you are not allowed to know that.
Indeterminacy is as close to concurrency as we can get with
a sequential program and its vital not only for optimisation,
but to ensure the programmer does not get bogged down depending
on implementation details.

So now that you understand reachability, you will begin to 
understand what happens when a fibre starves. Provided there
is no active fibre which can reach the channel, then since
the only object which can reach the fibre is the channel,
which is unreachable, the starving fibre is also unreachable.
So it is garbage collected!

Note {\em very carefully} that it is {\em absolutely essential}
that channels only be reachable by fibres that wil use them.
Go back and look carefully at the \verb%doit% procedure:

\begin{minted}{felix}
proc doit () {
  var ich1, och1 = mk_ioschannel_pair[int]();
  var ich2, och2 = mk_ioschannel_pair[int]();
  var p = producer och1;
  var t = transducer (ich1, och2);
  var c = consumer (ich2);
  spawn_fthread p;
  spawn_fthread t;
  spawn_fthread c;
}
doit();
\end{minted}

The four channel end points are known to this procedure, so whilst
this procedure is active, those channels are reachable. Indeed
the three closures \verb%p,t,c% are bound to these channels,
and the procedure knows them too. So the fibres spawned by this
procedure may be reachable whilst the procedure itself is active.

Now, when you spawn a fibre, what happens? Does the spawned fibre
run immediately, or does the spawning procedure continue?

Did you guess? In the abstract semantics, it is indeterminate!
You're not allowed to design code that depends on which one runs
first. In Felix, the spawned procedure runs first, but that's an
implementation detail!

So what happens here is that sometime or other, the procedure
will return, and the channels it could reach will no longer be
reachable because the procedure's local data frame is no longer reachable.

And then, the procedure's data frame will be reaped by the collector,
and, when the spawned fibres finally terminate, starve or block, they will
also be reaped.

If you're getting the picture you may well wonder how the program
as a whole terminates, and the answer is: in Felix the mainline
is a coroutine! It is not a subroutine. In fact in Felix,
all subroutines are, in the abstract, coroutines. The normal
procedural subroutines are just coroutines that do not do channel I/O.

\chapter{Coroutine Basics}

\section{Syntax Extensions}
Felix has two syntax extensions designed to so coroutines are easier to use.

\subsection{The {\tt chip} definition}
This extensions encourages a picture of coroutines as integrated
circuits, even though that is not really accurate.

\phantomsection
\label{fig:prodtranscons1}
\begin{minted}{felix}
chip producer 
  connector io
    pin out: %>int
{
  for i in 0..<10 
    perform write (io.out, i);
}
\end{minted}
\begin{minted}{felix}
chip transducer 
  connector io
    pin inp: %<int
    pin out: %>int 
{
  while true do
    var x = read io.inp;
    var y = x * x;
    write (io.out, y);
  done
}
\end{minted}
\begin{minted}{felix}
chip consumer 
  connector io
    pin inp: %<int
{
  while true do
    var y = read io.inp;
    println y;
  done
}
\end{minted}

Here \verb%connector% names an argument to the procedure
of record type. The fields of the record and specified with
the \verb%pin% clause. You can have more than one connector
phrase, each specifies a separate argument. Each \verb%chip%
has an aditional unit argument added automatically. The signatures
of the three chips above are:

\begin{minted}{felix}
  producer: (out: %out) -> 1 -> 0
  transducer: (inp: %<int, out: %out) -> 1 -> 0
  consumer: (inp: %<int) -> 1 -> 0
\end{minted}

Note that this syntax uses a record type for the connector,
whereas our original coroutines used a plain type for one
parameter and a tuple for the two required for the transducer.

\subsection{The {\tt device} statement}
You can write:

\begin{minted}{felix}
device x = y;
\end{minted}

to construct a procedure closure of type \verb%unit->void%.
Actually, device is just a synonym for \verb%var%, and is
provided to make your look more like an electrical engineer
than a software engineer.


\subsection{The {\tt circuit} statement}
\subsubsection{The {\tt connect} clause}
A \verb%circuit% statement can be used to connect devices
and pins. It is an executable statement!

\begin{figure}[h]
\begin{minted}{felix}
circuit
  connect producer.out, transducer.inp
  connect transducer.out, consumer.inp
endcircuit
\end{minted}
\caption{Simple circuit connection}
\label{fig:circ1}
\end{figure}

This makes a pipeline from the chips. The connecting channels
are automatically created, as are the procedure closures required
to make devices. The resulting devices are then spawned.

You can list any number of comma separated device/pin pairs
in a connect clause. Felix finds the transitive closure of
connections and makes a channel to connect all those pins together.
The data type of all connected pins must be the same. If all are inputs
or all are outputs, the compiler will issue a warning (but it is not
an error!).

\subsubsection{The {\tt wire} clause}
There is also another clause you can use in a circuit statement:

\begin{minted}{felix}
circuit
  wire ch to dev.pin
endcircuit
\end{minted}

The \verb%wire% clause allows you to connect a known channel to a device.

\chapter{Core Components}
Every system needs a library! 
\section{Base Components}
\subsection{Blockers}
Here is a device to use when you have to connected
a writer to a channel, but want it to be unconnected.

\begin{minted}{felix}
chip writeblock[T]
  connector io
    pin inp : %<T
{
}
\end{minted}

And the corresponding reader:

\begin{minted}{felix}
chip readblock[T]
  connector io
    pin out: %>T
{
}
\end{minted}

These coroutines suicide immediately, so a writer is blocked,
or a reader starved, respectively.

\subsection{Universals}
This chip reads input forever but ignores it.

\begin{minted}{felix}
chip sink[T]
  connector io
    pin inp : %<T
{
  while true do
    var x = read (io.inp);
    C_hack::ignore (x);
  done
}
\end{minted}

The \verb%C_hack::ignore% procedure is a trick
which forces the read to occur. In Felix, if a variable is unused
it is optimised away --- along with its initialiser. In this case
the initialiser is the read operation, which has a crucial and intended
side effect so we don't want it optimised away. The ignore procedure
throws away an unwanted result of a computation, without throwing
away the computation itself. So the read will be performed,
even though we don't care what the returned value is.
In Felix it is always safe to throw away application of a function
is the result is not used, since functions are not allowed to
have any side effects. However read is a generator not a function.

The result of a generator must be used otherwise the generator
application will be thrown away. This changes the program semantics.
Felix does this deliberately, it is not a bug but a feature.
A particularly important case is assigning a clock to a variable.
Doing that can dynamically load the asynchronous I/O subsystem
and start an event monitoring thread. But if the variable is not
used, the clock isn't constructed, and the program may run without
requiring the asynchronous I/O system. The system is loaded on demand,
and the semantics ensure the demand propagates from the use of a feature
requiring the system, the semantics also ensures resources aren't
acquired {\em unless} they're needed.

This chip writes a fixed value forever.
It is the analogue of a value or constant function:

\begin{minted}{felix}
chip source[T] (a:T)
  connector io
    pin out: %>T
{
  while true perform write (io.out, a);
}
\end{minted}

\subsection{Adaptors}
Two key adaptors provide {\em lifts}\index{lift}:


\index[codeindex]{source\_from\_list}
\index[codeindex]{bound\_source\_from\_list}
\begin{minted}{felix}
chip source_from_list[T] (a:list[T])
  connector io
    pin out: %>T
{
  for y in a perform write (io.out,y);
}

chip bound_source_from_list[T] (a:list[T])
  connector io
    pin out: %>opt[T]
{
  for y in a perform write (io.out,Some y);
  while true perform write None[T];
}
\end{minted}

A lift is a way to go from the imperative/functional model
of the world into the coroutine/stream model. These
two chips lift a list into a stream. That is, it translates
spatial, inductive, data into temporal, coinductive, codata.

It is absolutely vital to understand how these two
lifts differ. The first lift is a pure lift
which simply starves any read trying to go past the
end of the list. There is no terminal value to tell the
reader the list has ended. Notice a finite number
of values is written by the first device, equal to the
number in the list. This is a {\em finite stream}.

The second device generates an infinite stream
by embedding a finite list in its head using 
an option type. The tail of the stream is an infinite
list of None's. The None values are terminators which
act to bound the list.

I will warn now, to understand how to use the first device
requires a {\em paradigm shift}. Having things drop dead without
any warning seems difficult to manage if you're used
to dealing with inductive data types in a functional
setting. We will see later, however, that it is natural.

Next, we have a basic adaptor for a function.

\index[codeindex]{function}
\begin{minted}{felix}
chip function[D,C] (f:D->C)
  connector io
    pin inp: %<D
    pin out: %>C
{
  while true do
    var x = read io.inp;
    var y = f x; 
    write (io.out, y);
  done
}
\end{minted}


This device is an example of the generic category 
of a {\em transducer}.  

And here is a basic adaptor for a procedure:

\begin{minted}{felix}
chip procedure[D] (p:D->0)
  connector io
    pin inp: %<D
{
  while true do 
    var x = read io.inp;
    p x;
  done
}
\end{minted}

which is an example of the generic category {\em sink}.

\subsection{Filter}
Another useful chip is the filter, the first variant
uses a condition on the input, if it passes then the
function is applied to the input value to produce
the output value, otherwise the value is ignored:

\begin{minted}{felix}
chip filter[D,C] (c:D->bool) (f:D->C)
  connector io
    pin inp: %<D
    pin out: %>C
{
  while true do
    var x = read io.inp;
    if c x do
       write (io.out, f x);
    done
  done
}
\end{minted}

The second variant just uses a function with codomain
of an option type:

\begin{minted}{felix}
chip filter[D,C] (f:D->opt[C])
  connector io
    pin inp: %<D
    pin out: %>C
{
  while true do
    var x = read io.inp;
    match f x with
    | Some y => write (io.out, y);
    | None => ;
    endmatch;
  done
}
\end{minted}

Another special filter is:

\begin{minted}{felix}
chip oneshot [T]
  connector io
    pin inp: %<T
    pin out: %>T
{
  write (io.out, read io.inp);
}
\end{minted}

Filters are transducers whose equivalent mathematical entity is
a partial function. This is relation for which not all values in
the domain have a corresponding value in the codomain.
You can upgrade a partial function to a function in several ways,
the two most common being to restrict the domain to the values for which
the partial function is defined, or, to extend the codomain with an
error value which if mapped to, indicates the original partial
function was not defined for that argument.

Unfortunately both these methods have a serious fault: they change
the type of the partial function so it can no longer be composed
with other functional entites. Some systems leave the type alone
and throw an exception which turns out to be even more nasty.

Other systems systematically extend all functions to include
the error value in both domains and codomains by using a monad.
However whilst this restores composability of the extended
operators, the monads themselves cannot be easily combined.

The correct solution for a functional language,
and there is only one correct solution, is exactly what C
does: nothing! It is up to the programmer, without help
from the type system, to ensure that the partial function
is not called with a value for which it is not defined.
The set of defined values is sometimes represented by
a precondition, which can be either just documentation,
checked at run time, or in limited cases, checked at
compile time.

Dependent typing systems extend the usual limitations of the
compile time checks by requiring the client programmer
supply suitable proof sketches. 

Felix allows preconditions written using the \verb%when%
clause like this:

\begin{minted}{felix}
fun safe_divide (x:int, y:int when y != 0) => x/y;
\end{minted}

The precondition is checked at run time.

\section{Synchronising drops with {\tt run}}
An {\em drop}\index{drop} is the opposite of a lift.
It translates codata into data, that it, it translates
temporal ordering into a spatial ordering.

\subsection{List drop}
A special case of the \verb%procedure% chip is a list drop:

\begin{minted}{felix}
chip sink_to_list[T] (p: &list[T])
  connector io
    pin inp : %<T
{
  while true do
    var x = read (io.inp);
    p <- Cons (x,*p);
  done
}
\end{minted}

It translates a stream into a list. That is, values arriving over time
are stored, latest first, into a spatial data type.

Now, we need an example to show how to use this drop!

\begin{minted}{felix}
include "std/control/chips";
open BaseChips;

var output = Empty[int];

device s = source_from_list ([1,2,3,4]);
device tr = function (fun (x:int)=>x*x);
device d = sink_to_list &output;
run  { 
  circuit
    connect s.out, tr.inp
    connect tr.out, d.inp
  endcircuit
};
println$ output;
\end{minted}
 
The critical thing to note is the \verb%run% procedure.
It spawns its argument procedure as the initial fibre
of a new fibre scheduler, and then waits until that scheduler
terminates due to a lack of active fibres.

So {\em within} the fibre system, we cannot detect the end
of the list, but from outside, we can detect it indirectly
by the fact that our circuit is no longer active.

The \verb%run% procedure first lifts out of the current
procedural/imperative mode into fibrated stream mode,
waits until it completes, and then drops back to procedural
mode. In other words it interfaces the two modes.

\verb%run% can be used in a procedure, in a coroutine,
or in a function. Run, in effect,  creates and pushes a scheduler
on a scheduler stack, waits until it completes, and then pops
back to the current scheduler.

\section{Symmetric Model}
We have encountered now two operations, lifts and drops,
which translate from space to time, and time to space, respectively.
In general a source is a lifted value, and a sink is a dropped value.

In the functional world, we usually deal with three kinds of entities:
a value of a type, which is an element of a set. We apply mysterious
things called functions to values to obtain new values. 

Values can also be fed into the computation representing the rest of the program,
which is called a continuation. When you apply a function, 
the code to be done afterwards, which accepts the result, is the 
continuation of the application. In a procedural setting, the continuation
can be thought of as being represented by the return address, which
is invoked by the \verb%return% statement. In fact the return address
is secretly passed to the procedure along with the argument, just
so that the return statement know where to return to.

Another view is that calling a subroutine suspends the caller,
invokes the callee, which, when finished, resumes the caller
just after the call. With functions, the continuation is not,
however complete, it must be passed the result of the function
call before it can continue.

In this model of the world, we like to think about passing
continuations to routines so they know what to do when their
part of the job is done. When code is written such that
continuations are explicitly passed around, it is called
CPS or Continuation Passing Style.

Having learned about coroutines and how they work you may
begin to see how synchronous channels act to pass continuations.
A fibre suspended on a channel, waiting for matching I/O
operation from another fibre is precisely a continuation. 


\section{Avoiding lockup}
To avoid some cases of lockup we provide the buffer device:

\begin{minted}{felix}
chip buffer [T]
  connector io
    pin inp: %<T
    pin out: %>T
{
  while true do
    var x = read io.inp;
    write (io.out, x);
  done
}
\end{minted}

You can see this is a just a copy operation and is a special
case of the \verb%function% chip, which uses the identity
function. However in a fibrated setting, \verb%buffer% is not
semantically a no operation.

Here's an example:

\begin{minted}{felix}
include "std/control/chips";
open BaseChips;

chip out2
  connector io
    pin oa: %>int
    pin ob: %>int
{
  write (io.oa, 11);
  write (io.ob, 42);
}

chip in2 
  connector io
    pin ia: %<int
    pin ib: %<int
{
   var a = read a;
   var b = read b;
   println $ a - b;
}

// WOOPS, lock up!
//circuit
//   connect out2.ob, in2.ia
//   connect out2.oa, in2.ib
//endcircuit

device abuf = buffer;
device bbuf = buffer;
circuit
   connect out2.ob, bufb.inp
   connect out2.oa, bufa.inp
   connect in2.a, bufa.out
   connect in2.b, bufb.out
endcircuit
\end{minted}

This is a classic deadlock for threads. The writer writes $a$
first then $b$, then reader reads $b$ first, then $a$.
Adding the buffers removes the ordering dependency.
I added two buffers, although in this case only one is
required. Can you figure out which two pins have to connected
via a buffer?

Here is another useful chip, it copies a single value
from input to output then suicides. It is generally useful
to insert into pipelines that would otherwise be continuous
when you only want a one shot operation.

Finally here are some convenience types:

\begin{minted}{felix}
typedef iopair_t[D,C] = (inp: %<D, out: %>C);

// source
typedef ochip_t[T] = (out: %>T) -> 1 -> 0;

// transducer
typedef iochip_t[D,C] = iopair_t[D,C] -> 1 -> 0;

// sink
typedef ichip_t[T] = (inp: %<T) -> 1 -> 0;

\end{minted}

which specify the type of three commonly used chips.

\chapter{Pipelines}
One of the most basic control structures you can build with
coroutines is the {\em pipeline}. This is a series connection
of transducers, the output of the left one of a pair connected
to the input of the right one. A pipeline of transducers is said
to be an {\em open pipeline}.

If a source is connected to the left end, and a sink to the right
end, it is a closed pipeline.

An open pipeline is semantically equivalent to a transucer with
additional buffering. A pipline closed on the left is a source,
and a pipeline closed on the right is a sink.
The syntax |-> is parsed to pipe (a,b).
We add overloads for chips with pins
named io.inp, io.out.

Here are the binary combinators:

This chip connects two transducers to form a new
transducer. Note, since we use the \verb%circuit%
statement, the pair of component coroutines are
actually spawned as fibres.

\begin{minted}{felix}
chip pipe[T,U,V] (a:iochip_t[T,U],b:iochip_t[U,V])
 connector io
   pin inp: %<T
   pin out: %>V
{
  circuit
    connect a.out,b.inp
    wire io.inp to a.inp
    wire io.out to b.out
  endcircuit
}
\end{minted}

Here we connect a source to a transducer to make
a new source:

\begin{minted}{felix}
chip pipe[T,U] (a:ochip_t[T],b:iochip_t[T,U])
 connector io
   pin out: %>U
{
  circuit
    connect a.out,b.inp
    wire io.out to b.out
  endcircuit
}
\end{minted}

Here, a transducer is connected to a sink
to form a new sink.

\begin{minted}{felix}
chip pipe[T,U] (a:iochip_t[T,U],b:ichip_t[U])
 connector io
   pin inp: %<T
{
  circuit
    connect a.out,b.inp
    wire io.inp to a.inp
  endcircuit
}
\end{minted}

Finally, connecting a source to a sink results in
a closed pipeline. Closed pipelines are equivalent in
some sense to subroutines in that they can only be observed
for their side effects.

\begin{minted}{felix}
// source to sink
proc pipe[T] (a:ochip_t[T],b:ichip_t[T])
{
  circuit
    connect a.out,b.inp
  endcircuit
}
\end{minted}

Note carefully, this last operator is a procedure not a chip!

Felix provides the infix symbol \verb%|->% for the \verb%pipe% operator.
An example of use, we can say:

\begin{minted}{felix}
producer |-> transducer |-> consumer;
\end{minted}

given the chips of \ref{fig:prodtranscons1}
instead of the circuit statemnent \ref{fig:circ1}.

\subsection{The lift functor}
Pipelining is associative up to buffering. The exact structures 
spawned may differ and the order of execution may differ, but
the ordering always conforms to the abstract semantics.

There is a mapping between function compositions and pipelines,
and this mapping is structure preserving. Given a sequence of
functions of types suitable for composition
$$f_1, f_2, f_3 \dots$$
then writing $\Phi$ for the \verb%function% chip, we have
$$\Phi(f_1 \odot f_2 \odot f_3 \dots) \cong
\Phi f_1 \mapsto \Phi f_2 \mapsto \Phi f_3 \dots)
$$
where $\odot$ is reverse function composition.

In other words, it is structure preserving, and thus a categorical {\em functor}.
It is called the {\em lift} functor because it lifts functional
code into cofunctional code, that is, functional stuff is lifted
into semantically equivalent coroutine based code. You can also drop
any pipeline to a function composition, so the two systems
are isomorphic.

The key point, which we are yet to demonstrate, is that
pipelines are not the only kind of circuits you can make.
Cofunctional programming {\em subsumes} functional programming.
Its more flexible and more powerful.

\subsection{Pipeline from list}

This chip allows dynamic construction of an open pipeline from
a non-empty list of transducers.

\begin{minted}{felix}
chip pipeline_list[T] (a: list[iochip_t[T,T]])
  connector io
    pin inp: %<T
    pin out: %>T
{
  proc aux (lst:list[iochip_t[T,T]]) (inp: %<T) {
    match lst with
    | h1 ! h2 ! tail =>
      var inchan,outchan = mk_ioschannel_pair[T]();
      spawn_fthread$  h1 (inp=inp, out=outchan);
      aux (h2!tail) inchan;
    | h1 ! _ =>
      spawn_fthread$  h1 (inp=inp, out=io.out);
    endmatch;
  }
  aux a io.inp;
}
\end{minted}

\section{Acyclic Flow}
Acyclic flow circuits are an extension of the pipeline
concept which allows data to flow from sources to sinks
in an acyclic network. Lets look at an example with two
sources:

\begin{minted}{felix}
device A = source_from_list ([1,2,3]);
device B = source_from_list ([5,6,7]);
chip add
  connector io
    a: %<int
    b: %>int
    sum: %>int
{
  while true do
    var a = read io.a;
    var b = read io.b;
    write (io.sum, a + b);
  done
}
circuit
  connect A.out, add.a
  connect B.out, add.b
  connect add.sum, consumer.inp
endciruit
\end{minted}

where we have used our original consumer to print the results.
There is an important thing to observe here: the order in which
our \verb%add% chip reads it input does not matter {\em in
this case} because it is connected to two {\em independent} sources.

You can probably see that given any binary operators represented
as chips, we can construct a calculate with a tree like structure
to perform the calculation.

\begin{minted}{felix}
chip sub
  connector io
    a: %<int
    b: %>int
    diff: %>int
{
  while true do
    var a = read io.a;
    var b = read io.b;
    write (io.diff, a - b);
  done
}
\end{minted}


If you are familiar with functional programming concepts, you may
ask whether these functions are eagerly or lazily evaluated.
Eager evaluation means the arguments are evaluated first,
before the function is called, so if such an evaluation fails
to terminate, the function call never happens, and we can say that
the whole application fails to terminate.

With lazy evaluation, the arguments are only evaluated when they're
actually needed. So if an argument which would be nonterminating
is not actually needed, the function application can still succeed.

Because coroutines provide explicit control flow, the evaluation
strategy depends on the way you write the coroutine. To put this
another way, there is no built in preference for either eager or
lazy evaluation. We will demonstrate by showing an important
operator written two different ways. First the eager variant:

\begin{minted}{felix}
chip eagerconditional
  connector io
    pin condition: %<bool
    pin trueval: %<int
    pin falseval: %<int
    pin result: %>int
{
  var c = read io.condition;
  var t = read io.trueval;
  var f = read io.falseval;
  write (io.result, if c then t else f);
}
\end{minted}

and now the lazy variant:

\begin{minted}{felix}
chip lazyconditional
  connector io
    pin condition: %<bool
    pin trueval: %<int
    pin falseval: %<int
    pin result: %>int
{
  var c = read io.condition;
  if c do
    var t = read io.trueval;
    write (io.result, t);
  else 
    var f = read io.falseval;
    write (io.result, t);
  done
}
\end{minted}

If the eager chip starves on either the read of the true value
or the false value, then any reader of the result also starves,
no matter what is read for the condition. However the lazy
chip only ever reads the value it is required to output,
and so only starves if the the read on that channel starves.
If it doesn't, then it doesn't matter if a read on the
other channel starves, because we never actually read it.

Another interesting chip is this one:

\begin{minted}{felix}
chip choose
  connector io
    pin condition: %<bool
    pin value: <%int
    pin truecont: %>int
    pin falsecont: %>int
{
  var c = read io.condition;
  var v = io.value;
  if c do
    write (io.truecont, v);
  else
    write (io.falsecont, v);
  done
}
\end{minted}

This is a very important chip to understand! What it does is read
a condition and a value and write that value down one of two 
channels, depending on the condition.

At the other end of the two outputs
there may well be two different chips reading the result,
one to handle each of the two conditions. So this chip is like
a conditional goto chip, or a switch, in that it choses how
the rest of the program will proceed by selecting a data
path. Whichever path is chosen, the continuation suspended
at the end of the channel will continue execution. So passing
an output channel to a chip is an abstract way of passing
a continuation.

I say abstract because the actual chip which resumes control
on reading a value from the channel is dependent entirely
on how the circuit is connected. It doesn't depend on the
actual channel passed directly, but what is connected to
the other end.

Critically, the \verb%choose% chip enforces lazy evaluation
because only one of the channels is written to, what's
connected to the other end will only be activated if its 
input channel is selected for the write. In particular
I want you, the reader, to see that channels are not
merely ways to send data around, rather, they're ways to
transmit {\em control}. In particular, networks of connected
chips have a shape called a {\em control structure}.

So now we have looked at extensions to the pipeline concept
in which we have chips with multiple inputs and outputs,
and we are going to demonstrate how to handle the partial
function division:

\begin{minted}{felix}
chip divide
  connector io
    pin numerator: %<int
    pin denominator: %<int
    pin quotient: %>int
    pin divisionbyzero: %>int
{
  var n = read io.numerator;
  var d = read io.denominator;
  if d == 0 do
     write (io.divisionbyzero, numerator);
  else
     write (io.quotient, numerator/denominator);
  done
}
\end{minted}

This is an important chip because it shows how to handle
a partial function correctly, by providing an error channel.

Imagine we have to compute the formula:
$${x + y\over x - y}+1$$
We can use this:

\begin{minted}{felix}
var x = 1;
var y = 1;
device xc = x.source;
device yc = y.source;
device one = 1.source;

device add1 = add;
device add2 = add;

chip error
  connector io
    pin inp: %>int
{
  var x = read io.inp;
  println "Division of " + x.str + " by zero";
}

circuit
  connect add1.a, xc.out
  connect add1.b, yc.out
  connect sub.a, xc.out
  connect sub.b, yc.out
  connect div.numerator, add1.sum
  connect div.denominator, sub.diff
  connect div.quotient, add2.a
  connect one.out, add2.b
  connect add.sum, consumer.inp 
  connect div.divisionbyzero, error.inp
endciruit
\end{minted}

\begin{figure}[h]
\begin{center}
\tikzstyle{cell} = [rectangle,minimum width=0.7cm,minimum height=0.5cm,text centered,draw=black]
\tikzstyle{arrow} = [thick,->,>-stealth]
\begin{tikzpicture}[node distance=3cm]
\node(O)[cell]{1};
\node(X)[cell,below of=O]{x};
\node(Y)[cell, below of=X]{y};
\node(A1)[cell,right of=X]{add};
\node(S)[cell,right of=Y]{sub};
\node(D)[cell,right of=S]{div};
\node(A2)[cell,right of=D]{add};
\node(C)[cell,right of=A2]{consumer};
\node(E)[cell,below of=D]{error};
%\node(B)[cell,right of=A]{B};
%\node(C)[cell,right of=B]{C};
\draw[arrow](X) -- (A1);
\draw[arrow](Y) -- (A1);
\draw[arrow](A1) -- (D);
\draw[arrow](X) -- (S);
\draw[arrow](Y) -- (S);
\draw[arrow](S) -- (D);
\draw[arrow](D) -- (A2);
\draw[arrow](D) -- (E);
\draw[arrow](O) -- (A2);
\draw[arrow](A2) -- (C);
\end{tikzpicture}
\caption{Flow in simple formula}
\label{fig:flowinsimpleformula}
\end{center}
\end{figure}

This looks complicated, but look at the diagran shown in \ref{fig:flowinsimpleformula}.
There are some tricks in the code: the \verb%x% and \verb%y% sources are reused, 
which is only safe because they're constant sources, and the \verb%add%, \verb%sub%,
and \verb%div% chips are one shots.

Exercise (Hard). If we wanted to make this system accept a list of pairs and process them,
printing the values of x and y and the quotient, or an error message,
what would we need to do?

\section{Multi Writer}
The following chip is a vital component with an interesting
structure:

\begin{minted}{felix}
chip tryall_list[D,C with Str[D]] (a: list[iochip_t[D,C]]) 
  connector io
    pin inp: %<D
    pin out: %>C
{
  while true do
    var x = read io.inp;
    for h in a do
      var lin,lout = mk_ioschannel_pair[D]();
      spawn_fthread (h (inp=lin, out=io.out));
      write (lout,x);
    done
  done
}
\end{minted}

Clearly, it repeatedly reads a value from its input channel,
and writes the value down all the output channels in the 
supplied list. Getting that work as specified was not easy!

You may think, you could just read a value and write down all
the channels. But this does not work because one of the channels
may block the write, and then the whole chip is frozen up!
So we have to spawn a new fibre for each value and each channel
so that if the channel is blocked, the other writes can proceed.

What this means, however, is that, because the channel is reachable
from the chip, whilst any one channel is not blocked, attempts to write
will be stacked up for every input on every blocked channel. 

\section{Filter}
...

\chapter{Base Recognisers}
In this chapter we introduce a data structure used for scanning strings,
some specific primitive recognisers, and some general purpose chips which
can be used as recogniser combinators.

The idea of a recogniser is that you have a string, and want to see if
it matches a regular expression. So what we do is pass to the recogniser
a pointer into the string. The recogniser chips reads the pointer
and examines the string from that point to see if some of the string
after that pointer matches what the chip is supposed to recognise,
and if so, it writes out a pointer to the first character in the
string which does not match.

But here is where you have to make the big paradigm shift!
If the chip doesn't recognise anything at the location the
pointer indicates, it doesn't write anything! 

This is quite different behaviour from a function! A function would
return an option type, saying \verb%Some p% if it recognised something
and returning a pointer \verb%p% to the first unrecognised character,
or \verb%None% if it didn't recognise anything. Functions always have
to output something! If they didn't, the function would be non-terminating,
and that means an infinite loop would cause the whole program to fail.

Coroutines, on the other hand, regularly report failure by keeping
quiet! They don't know what to do, so they do nothing.

\section{Buffers}
Now, here is the kind of pointer to the string we will use,
for some reason its called a \verb%Buffer%.


\begin{minted}{felix}
struct Buffer
{
  sp: varray[char];
  pos: int;

  fun atend => self.pos >= self.sp.len.int;

  fun get => 
    if self.atend then char "" 
    else (self.sp) . (self.pos)
  ;

  proc next { 
    if not self*.atend do
      pre_incr self.pos;
    done
  }

  fun advanced =>
    if self.atend then self
    else Buffer (self.sp, self.pos + 1)
  ;

  fun lookahead (i:int) =>
    if self.pos + i > self.sp.len.int then char ""
    elif self.pos + i < 0 then char ""
    else (self.sp) . (self.pos + i)
  ;
}
\end{minted}

Two instance variables make a \verb%Buffer%, a \verb%varray% of \verb%char% called 
\verb%sp%, for the string and an \verb%int% named \verb%pos% for as an index into
the string to mark the current position. The array is represented by a pointer
and its contents will not be changed during processing.

The \verb%atend% method detects if the current position is just after the last
character. The \verb%get% method gets the current character as a string,
or returns the empty string at the end.

The \verb%next% method is mutator that increments the current position if it
is not at the end, wherease the \verb%advanced% method returns a copy of the 
object advanced one, or at the same position if it is at end, this method
is purely functional.

Finallyu the \verb%lookahead% method returns the character \verb%i% positions ahead
of the current position, if there is one, or an empty string if that position is
past the end.

We also provide some constructors:

\begin{minted}{felix}
ctor Buffer (p:varray[char]) =>
  Buffer (p,0)
;

ctor Buffer (p:string) =>
  Buffer (p.varray[char],0)
;

ctor Buffer (p: &string) =>
  Buffer (*p)
;
\end{minted}

a conversion to a printable string representation:

\begin{minted}{felix}
instance Str[Buffer] {
  fun str (b:Buffer) => "@"+b.pos.str;
}
\end{minted}

and an equality operator which ignores the underlying
string and just compares the positions.

\begin{minted}{felix}
// hack, ignore underlying data.. FIXME
instance Eq[Buffer] {
  fun == (a:Buffer, b:Buffer) => a.pos == b.pos;
}
\end{minted}

It isn't really correct but it will do for our purposes,
if the base strings are distinct the buffers are aren't
really comparable.

Finally a simularly hacked extractor finds the string
between two positions, including the first position
and excluding the second:

\begin{minted}{felix}
ctor string (a:Buffer, b:Buffer) =
{
  var x = "";
  for i in a.pos ..< b.pos do
    x += a.sp.i;
  done
  return x;
}
\end{minted}

Now we have a the data type which will be transmitted along channels
of the recogniser circuit, we can define it by

\begin{minted}{felix}
typedef recog_t = BaseChips::iochip_t[Buffer,Buffer];
\end{minted}

which says that a \verb%recog_t% is just a chip which takes
an input \verb%Buffer% value, tries to recognise a part of the
underlying string starting at the input position, and writes
out the position just past the end of the recognised substring,
if one exists. 

Note that if we don't recognise anything,
nothing is written, the chip just cycles around and tries
again with another input. This behaviour is not evident from
the data type, it would be approximated in the control
type if we have a system for control types, but we don't.
On failure, coroutines typically either do nothing or
write on a special error channel allowing a normal or alternate
continuation to take further action. 

In our parser we specially want failures to have no consequences! 
Unlike functional code, failure doesn't return an error code to
the caller, requiring the caller to check it. Rather, it simply
fails to propagate and translate information, allowing the algorithm
to continue exploring successful paths and allowing failure paths
to simply die off without ceremony. You don't need an exception
to abort a computation. 

In principle, this is like a non-returning function, however since
computations are built from many interconnected {\em active}
fibres, non-completion is not only not undesirable, it
is the {\em prefered method} of constructing algorithms!

\section{Primitives}
We now present some basic primitive recognisers.
\subsection{String matcher}
This chip just matches its argument as a string.

\begin{minted}{felix}
chip match_string (s:string)
  connector io
    pin inp: %<Buffer
    pin out: %>Buffer
{
nextmatch:>
  var b = read io.inp;
  for i in 0..< s.len.int do 
    if s.[i] != b.get goto nextmatch;
    b&.next;
  done
  write (io.out, b);
  goto nextmatch;  
}
\end{minted}

The code reads a string position represented by a \verb%Buffer%,
and tries to match the argument string. If it does, it writes
out the position one past the end of the matched substring,
otherwise it does nothing. In either case it then goes back
and reads another position and tries again.



\subsection{Whitespace matcher}
This transducer matches a sequence of whitespace
characters, defined as any character less that or
equal to a space character. It always succeeds,
that is, if there is no white space character at 
the current position, it just returns the current 
position. That is, it is a {\em total function}.

\begin{minted}{felix}
chip match_white 
  connector io
    pin inp: %<Buffer
    pin out: %>Buffer
{
  while true do
    var b = read io.inp;
    while not b.atend and b.get <= char ' ' 
      perform b&.next
    ;
    write (io.out,b);
  done
}
\end{minted}

\subsection{C++ comment matcher}
Matches two \verb%/% characters in succession,
followed by any sequence of characters, up
to and including the first newline character,
or, up to the end of the string.

This matcher also cannot fail, if it cannot match
a C++ comment it emits the input position.
It is a total function.

\begin{minted}{felix}
chip match_cxx_comment 
  connector io
    pin inp: %<Buffer
    pin out: %>Buffer
{
again:>
  var b = read io.inp;
  var b_saved = b;

  if b.get != char "/" goto bad;
  b&.next;

  if b.get != char "/" goto bad;
  b&.next;

  while not b.atend and not (b.get == char "\n")  perform b&.next;
  b&.next; // works fine even if atend
ok:>
  write (io.out,b);
  goto again;
bad:>
  write (io.out,b_saved);
  goto again;
}
\end{minted}

\subsection{Nested C comment matcher}
This is another total function that matches C style comments,
except that it also recognises nested comments. On the other hand 
it is a bit naive in that it also finds nested delimiters in 
enclosed C++ comments and strings.

\begin{minted}{felix}
chip match_nested_c_comment 
  connector io
    pin inp: %<Buffer
    pin out: %>Buffer
{
again:>
  var depth = 0;
  var b = read io.inp;
  var b_saved = b;
  if b.get != char "/" goto bad;
  b&.next;
  if b.get != char "*" goto bad;

nest:>
  b&.next;
  ++depth;

scan:>
  if b.get == "/" do // start nested comment
    b&.next;
    if b.get == "*" goto nest;
    goto scan;
  done

  if b.get == "*" do // end comment group
    b&.next;
    if b.get == "/" goto unnest;
    goto scan;
  done

  b&.next;
  goto scan;

unnest:>
  b&.next;
  --depth;
  if depth > 0 goto scan;
  write (io.out,b);
  goto again; 

bad:>
  write (io.out,b_saved);
  goto again;
}
\end{minted}

\subsection{Regular Expression matcher}
This is a generally useful matcher that uses
Felix system library binding of Google's RE2 package for matching. 

\begin{minted}{felix}
chip match_regex (r:RE2)
  connector io
    pin inp: %<Buffer
    pin out: %>Buffer
{
  while true do
    var b = read io.inp;
    var matched = varray[StringPiece] (1uz,StringPiece());
    var result = Match
      (
        r,StringPiece(b.sp),b.pos,
        ANCHOR_START,matched.stl_begin,1
      )
    ;
    if result do
      var b2 = Buffer (b.sp,b.pos+matched.0.len.int);
      write(io.out,b2);
    done
  done
}

device cident_matcher = 
  match_regex (RE2 "[A-Za-z][A-Za-z0-9_]*")
;
device decimal_integer_matcher = 
  match_regex (RE2 "[0-9]+")
;
\end{minted}

We also included a matcher for C identifiers which uses the regexp
matching chip, and simple decimal integer matcher.

\section{Delegators}
We present two versions of delegators, or proxies, which are chips that delegate
processing to another chip addressed by a pointer passed as an argument.
We will need delegation for forward referencing and recursion, when we need
the action of a chip that hasn't been defined yet.

The following transducer accepts a pointer to another chip and delegates
processing to the pointed at chip which is dereferenced each read,
allowing the target to be changed during processing:

\begin{minted}{felix}
chip deref_each_read[D,C] (p:&iochip_t[D,C]) 
  connector io
    pin inp: %<D
    pin out: %>C
{
  while true do
    var x = read io.inp;
    var rinp,rout = mk_ioschannel_pair[D]();
    spawn_fthread ((*p) (inp=rinp, out=io.out));
    // println$ "Deref_each_read: write " + io.out.address.str;
    write (rout,x);
  done
}
\end{minted}

Whereas this transducer also accepts a pointer to another chip
and delegates processing to the pointed at chip, but it only
dereferences the pointer once, after the first data is read.

\begin{minted}{felix}
chip deref_first_read[D,C] (p:&iochip_t[D,C]) 
  connector io
    pin inp: %<D
    pin out: %>C
{
  var x = read io.inp;
  var rinp,rout = mk_ioschannel_pair[D]();
  spawn_fthread ((*p) (inp=rinp, out=io.out));
  write (rout,x);
  while true do
    x = read io.inp;
    write (rout,x);
  done
}
\end{minted}

\section{Alternatives}
This chip is just a copy buffer with the name changed to epsilon, 
to suggest it recognises everything.

\begin{minted}{felix}
chip epsilon[T]
  connector io
   pin inp: %<T
   pin out: %>T
{
  while true do
    var x = read io.inp;
    write (io.out, x);
  done
}
\end{minted}


The optional chip uses \verb%tryall_list% to both pass some data through
unmodified, and also to pass it through modified by an arbitrary
transducer.

\begin{minted}{felix}
chip optional[T] (p:iochip_t[T,T])
  connector io
    pin inp: %<T
    pin out: %>T
{
  device both = tryall_list ([
    p,
    epsilon[T]
  ]);
  circuit
    wire io.inp to both.inp
    wire io.out to both.out
  endcircuit
}
\end{minted}

The \verb%oneormore_match% matches the regular expression A+.
It requires at least one match.

\begin{minted}{felix}
chip oneormore_matcher[T] (A:iochip_t[T,T]) 
connector chans 
  pin inp: %<T
  pin out: %>T
{
 device As = oneormore_matcher A;
 device As2 = pipeline_list (A,As).list; 
 device Ass = tryall_list (A, As2).list;
 circuit
   wire chans.inp to Ass.inp
   wire chans.out to Ass.out
 endcircuit
}
\end{minted}

And of course, this one matches A*.

\begin{minted}{felix}
chip zeroormore_matcher[T] (A:iochip_t[T,T]) 
connector chans 
  pin inp: %<T
  pin out: %>T
{
 device As = oneormore_matcher A;
 device Ass = tryall_list (epsilon[T], As).list;
 circuit
   wire chans.inp to Ass.inp
   wire chans.out to Ass.out
 endcircuit
}
\end{minted}

\chapter{Grammars}
We will now take a break from coroutines and do some functional
programming, because this is a fairly easy way to do the job
we have to do in preparation for the next section.

What we need is a representation of a grammar, because later in this
work we're going to show how to make a parser with coroutines.
Just to keep you on your toes, we're going to use a very powerful
functional programming technique known as {\em open recursion}.

\section{Grammar Datatype}
The first thing we need is a data structure representing a grammar:

\begin{minted}{felix}
typedef generic_gramentry_t[T] = string * T;
typedef generic_gramlib_t[T] = list[generic_gramentry_t[T]];
typedef generic_grammar_t[T] = string * generic_gramlib_t[T];
\end{minted}

What this says is that a grammar entry is a symbol, represented by
a string, which is used as an identifier, and some other 
information we're not specifying.  

A grammar library is a set of grammar entries. 
We're using a list because its easy. 

A grammar is a pair consisting of a grammar
library and a selected symbol called the {\em start symbol}.

Now, a grammar entry is intended to be a nonterminal and a production.
But we made the product a value of an unspecified type, \verb%T%
so we could fill in the details later. You will be surprised how
we do that! For now know that the secret of open recursion is to
first use a parameter to define a structure, and then later set
the parameter to that structure, so that initially the structure
is flat but parametrised, and the recursion is introduced by
setting the parameter to itself, establishing a cycle.

Now we're going to show you how to use this idea to find
the closure of the grammar. This is a list of all the symbols
reachable from the start symbol. 

The algorithm is a stock standard closure operation. Given some
symbol $r$, we find all the symbols $s1, s2, \dots$ it knows about
directly. We then add them to the set of known symbols, then pick
a symbol from the set we haven't examined before, and find out
what it knows about. We continue until we have examine all
the symbols, so that all the symbols they know about are already
in the set.

My algorithm splits the set in two pieces: ones we have already
examines and ones we have not. Each new symbol is added to the set
of symbols we do not know about. However we ignore a symbol
we have already seen, even if it isn't examined yet, since it
is already in one of the two sets.

Now you might ask .. indeed you should be asking .. how can we find
the symbols associated directly with a symbol $r$ if the associated
information is of an unknown type \verb%T%?

And the answer is: we can't! But the caller has to know how to find
all the symbols in a \verb%T% so we just require them to pass in
a function that can do it!

\begin{minted}{felix}
fun generic_cls[T] 
  (generic_add: list[string] -> T -> list[string])
  (lib:generic_gramlib_t[T]) 
  (unprocessed: list[string]) 
  (processed:list[string])
: list[string] 
=>
  match unprocessed with
  | Empty => processed
  | Cons (h,tail) =>
    if h in processed then 
      generic_cls generic_add lib tail processed 
    else
      match find lib h with
      | Some p =>
        let unprocessed = generic_add tail p in
        let p = Cons (h, processed) in
        generic_cls generic_add lib unprocessed p
      | None => 
        fun_fail[list[string]] ("MISSING NONTERMINAL " + h)
      endmatch
  endmatch
;

fun generic_closure[T] 
  (generic_add: list[string] -> T -> list[string])
  (g:generic_grammar_t[T]) 
: list[string] =>
  match g with
  | start, lib => 
    generic_cls generic_add lib ([start]) Empty[string]
;
\end{minted}

You may notice this algorithm doesn't do quite what I said it would:
we actually add all the associated symbols to the unprocessed set,
even if some of them are already processed. The reason is that the
check for this is done before looking for the associated symbols,
anyhow, so its equivalent to not needing the check and because
we didn't add the symbol to the unprocessed set. This simplifies
the requirements on the \verb%generic_add% function.

Ok, so now, we define the {\em concrete} type of a production we 
desire in two stages. We use open recursion! First we define
the flat, non-recursive form:

\begin{minted}{felix}
union open_prod_t[T] =
| Terminal of string * recog_t
| Nonterminal of string
| Epsilon
| Seq of list[T]
| Alt of list[T]
;
\end{minted}

and now we tie the recursive knot with a circular definition
which effects a fixpoint operation:

\begin{minted}{felix}
typedef prod_t = open_prod_t[prod_t];
\end{minted}

It takes a while to grok this! You may wonder why we didn't just
make the data type recursive in the first place. The answer is
profound and subtle: the flat structure we chose is easy to
extend by adding new cases, we can then fixate the extended
type. This leaves the original fixation unaffected, but it
makes the extended type recursive. In particular, the \verb%Seq%
and \verb%Alt% cases would allow lists of the extended type,
not just the original type, in other words, the extension
is {\em covariant} meaning the extension propagates to the
case arguments too.  This would not be the case if we extended
the original recursive type, because the recursive knot has
already been tied.

\subsubsection{Open/Closed Principle}
Open recursion is a technique which obeys a vital law of
modularity known as the {\em open/closed principle}, originally
espoused by Bertrand Meyer in Object Oriented Software Construction.
The principle states a module must be simultaneously closed so it
can be used, and open for extension. What is most interesting
is that classes in Object Orientation, proposed to support
this principle, where extension is by inheritance, actually
fail it, and precisely if a method of an base object with
an argument of the based type, that is, a binary operator,
is overridden in a derived class by a method with an argument
of the derived type, then the type system is unsound: the argument
must in fact be contravariant, but the requirement is for covariance.
This is known as the covariance problem and it destroys, utterly
and completely, the belief that object orientation is the basis
of a sound software development paradigm.

\subsubsection{Pretty Printer}
\begin{minted}{felix}
instance[T with Str[T]] Str[open_prod_t[T]] 
{
  fun str: open_prod_t[T] -> string =
  | Terminal (s,r) => '"' + s + '"'
  | Nonterminal name => name
  | Epsilon => "Eps"
  | Seq ss => "(" + catmap " " (str of T) ss + ")"
  | Alt ss => "[" + catmap " | " (str of T) ss + "]"
  ;
}
\end{minted}

\subsubsection{Reification}
\begin{minted}{felix}
typedef open_gramentry_t[T] = string * open_prod_t[T];
typedef open_gramlib_t[T] = list[open_gramentry_t[T]];
typedef open_grammar_t[T] = string * open_gramlib_t[T];


typedef gramentry_t = open_gramentry_t[prod_t];
typedef gramlib_t = open_gramlib_t[prod_t];
typedef grammar_t = open_grammar_t[prod_t];
\end{minted}

\begin{minted}{felix}
fun open_add_prod[T] 
  (aux: list[string] -> T -> list[string])
  (acc:list[string]) (p: open_prod_t[T]) 
: list[string] =>
  match p with
  | Terminal _ => acc
  | Nonterminal name => Cons (name, acc) 
  | Epsilon => acc
  | Seq ps => fold_left aux acc ps
  | Alt ps => fold_left aux acc ps
  endmatch
;
\end{minted}

\subsubsection{Construction}
\begin{minted}{felix}
fun add_prod(acc:list[string]) (p:prod_t) : list[string] =>
  fix open_add_prod[prod_t] acc p
;

\subsubsection{Reified Closure}
\begin{minted}{felix}
fun closure (g:grammar_t): list[string] =>
  generic_closure[prod_t] add_prod g
;
\end{minted}

\subsubsection{Nullable property}
A nonterminal is said to be {\em nullable} if it can produce
the empty string. We can calculate this inductively by observing
a nonterminal is nullable if one of its alternatives is the empty
string $\epsilon$ or a nullable nonterminal. Note this algorithm
assumes terminals can't be null!

In a conventional grammar, terminals are symbols, so it would be a
category error to even ask if they could be null, since they're not
strings by characters, a completely different type. However
we are constructing a scannerless parser, without tokenisation,
and a terminal is any computable nonempty string.


Calculate if a production RHS is nullable, depends on
knowing if a nonterminal is nullable.

\begin{minted}{felix}
fun nullable_prod 
  (lib:gramlib_t) 
  (e:prod_t) 
  (trail:list[string]) 
=>
  match e with
  | Terminal _ => false
  | Seq es => fold_left (fun (acc:bool) (sym:prod_t) => 
      acc and (nullable_prod lib sym trail)) true es

  | Alt es => fold_left (fun (acc:bool) (sym:prod_t) => 
      acc or (nullable_prod lib sym trail)) false es

  | Nonterminal nt => nullable_nt lib nt trail
  | Epsilon => true
;
\end{minted}

Calculate if a nonterminal is nullable, which depends on
knowing if a production is nullable.

\begin{minted}{felix}
fun nullable_nt 
  (lib: gramlib_t) 
  (nt:string) 
  (trail:list[string]) 
: bool =>
  if nt in trail then false else
  match find lib nt with
  | None => false
  | Some e => nullable_prod lib e (nt ! trail)
;
\end{minted}

Close the inductions with a base case.

\begin{minted}{felix}
fun is_nullable_prod (lib:gramlib_t) (e:prod_t) => 
  nullable_prod lib e Empty[string]
;

fun is_nullable_nt (lib:gramlib_t) (nt:string) => 
  nullable_nt lib nt Empty[string]
;
\end{minted}

\begin{minted}{felix}
fun recursive_prod 
  (lib:gramlib_t) 
  (e:prod_t) 
  (orig:string) 
  (trail:list[string]) 
=>
  match e with
  | Terminal _ => false
  | Seq es => 
    fold_left (fun (acc:bool) (sym:prod_t) => 
      acc or (recursive_prod lib sym orig trail)) false es

  | Alt es => 
    fold_left (fun (acc:bool) (sym:prod_t) => 
      acc or (recursive_prod lib sym orig trail)) false es

  | Nonterminal nt => 
    if nt == orig then true 
    else recursive_nt lib nt orig trail

  | Epsilon => false
;
\end{minted}

\subsection{Recursive Property}
A nonterminal is recursive if it can produce a sentential
form containing itself.

\begin{minted}{felix}
fun recursive_nt
  (lib: gramlib_t) 
  (nt:string) 
  (orig:string) 
  (trail:list[string]) 
: bool =>
  if nt in trail then false else
  match find lib nt with
  | None => false
  | Some e => recursive_prod lib e orig (nt ! trail)
;


fun is_recursive_nt (lib:gramlib_t) (nt:string) =>
  recursive_nt lib nt nt Empty[string]
;
\end{minted}

\subsection{Left Recursive Property}
A nonterminal is left recursive if it can produce a sentential
form in which the first symbol is itself.

\begin{minted}{felix}
fun left_recursive_prod 
  (lib:gramlib_t) 
  (e:prod_t) 
  (orig:string) 
  (trail:list[string]) 
=>
  match e with
  | Terminal _ => false

  | Seq es =>
    let fun aux (es:list[prod_t]) =>
      match es with
      | Empty => false
      | Cons (head, tail) => 
        if left_recursive_prod lib head orig trail then true
        elif is_nullable_prod lib head then aux tail
        else false
      endmatch
    in
    aux es

  | Alt es => fold_left (fun (acc:bool) (sym:prod_t) => 
      acc or (left_recursive_prod lib sym orig trail)) false es

  | Nonterminal nt => 
    if nt == orig then true 
    else left_recursive_nt lib nt orig trail

  | Epsilon => false 
;

fun left_recursive_nt 
  (lib: gramlib_t) 
  (nt:string) 
  (orig:string) 
  (trail:list[string]) 
: bool =>
  if nt in trail then false else
  match find lib nt with
  | None => false
  | Some e => left_recursive_prod lib e orig (nt ! trail)
;


fun is_left_recursive_nt (
  lib:gramlib_t) 
  (nt:string) 
=>
  left_recursive_nt lib nt nt Empty[string]
;
\end{minted}

\section{Normal Forms}
Our grammar uses a weakened EBNF form in which
we allow productions to contain expressions
using the \verb%Seq% and \verb%Alt% constructors.
However a conventional grammar requires production RHS
to only consist of a sequence of symbols, where
a symbol is either a terminal or nonterminal.
Optionally, some specifications also allow $\epsilon$
as the RHS of a nonterminal other than the start symbol.

The following routine unpacks a production library into a normal
form in which all \verb%Seq% and \verb%Alt% combinators have been
removed at the cost of introducing some fresh nonterminals with
synthesised names.

We do this by replacing each \verb%Seq% expression with a fresh 
nonterminal, and defining it to be the contents of the constructor.
An \verb%Alt% expression is also replaced by a fresh nonterminal,
which is defined by a series of productions of that nonterminal,
one RHS for each alternative.

The process is repeated until no \verb%Seq% or \verb%Alt% terms are left,
which leaves only epsilons, terminals, and nonterminals in
the library. The library is then said to be {\em flat} because
all the nesting is eliminated.


\begin{minted}{felix}
fun unpack 
  (fresh:1->string) 
  (head:string, p:prod_t) 
: gramlib_t =
{
 var out = Empty[gramentry_t];
 match p with
 | Epsilon => out = ([head,p]);
 | Terminal _ => out = ([head,Seq ([p])]);
 | Nonterminal s => out= ([head,Seq ([p])]);

 | Seq ps =>
   var newseq = Empty[prod_t];
   for term in ps do
     match term with
     | Epsilon => ;
     | Nonterminal _ => newseq = term ! newseq;
     | Terminal _ => newseq = term ! newseq;
     | _ =>
       var newhead = fresh();
       newseq = Nonterminal[prod_t] newhead ! newseq;
       out = unpack fresh (newhead,term);
     endmatch;
   done

   match newseq with 
   | Empty => out = (head,Epsilon[prod_t]) ! out;
   | _ => out = (head,Seq[prod_t] (rev newseq)) ! out;
   endmatch;

 | Alt ps =>
   iter 
     (proc (p:prod_t) { 
       out = unpack fresh (head,p) + out; 
     }) 
     ps
   ;
 endmatch;
 return out;
}

fun normalise_lib (fresh:1->string) (lib:gramlib_t) = {
  var normalised = Empty[gramentry_t];
  for p in lib perform
    normalised = unpack fresh p + normalised;
  return normalised; 
}

\end{minted}

\subsection{Another normal form}
The normal form produced above allows multiple alternatives
for a nonterminal to be scattered throughout the library,
making it hard to find a complete definition.

To fix this we provide another normal form in which
each symbol is defined exactly once. In principle,
the RHS of each definition will be a \verb%Alt%
term, however, we replace an empty \verb%Alt% with
$\epsilon$ and a singleton with only one alternative
with that alternative.

If the input to our routine is normalised by our first normalisation
procedure, then the output has the property that each of these
alternatives will be a non-empty list of symbols.

The result is then unique up to the order of the alternatives.

\begin{minted}{felix}
fun sort_merge (g:gramlib_t) : gramlib_t =>
 let 
   fun enlt 
     (a:gramentry_t, b:gramentry_t) 
   : bool => 
     a.0 < b.0 
 in
 merge (sort enlt g)
;
\end{minted}

\begin{minted}{felix}
fun merge (var p:gramlib_t): gramlib_t =
{
  if p.len == 0uz return p;

  var out: gramlib_t;

  var key: string;
  var alts = Empty[prod_t];
  var cur: gramentry_t;

  proc fetch() { 
    match p with 
    | Cons (head,tail) => cur = head; p = tail; 
    | Empty => assert false;
    endmatch;
  }

  proc dohead() { key = cur.0; alts = Empty[prod_t]; }
  proc dofoot() { out = (key,Alt alts) ! out;  }
  proc dobreak() { dofoot; dohead; }
  proc check() { if key != cur.0 call dobreak; }

  fetch;
  dohead;
  while p.len > 0uz do
    check;
    alts = cur.1 ! alts;
    fetch;
  done
  check;
  alts = cur.1 ! alts;
  dofoot;
  return out;
}
\end{minted}

\chapter{Recogniser from Grammar}
We are now read for the big job: to build a recogniser from
a grammar.

First we need a helper which finds the index of a 
nonterminal definition in an array of definition:

\begin{minted}{felix}
fun find (v:varray[ntdef_t]) (nt:string) : size = 
{
  for i in 0uz ..< v.len do
    if v.i.0 == nt return i;
  done
  assert false;
}
\end{minted}


Now the core function, which converts a production expression
into a recogniser. Because a function cannot use chip combinators
or fibration primitives, the function uses lazy evaluation: it
returns a procedure which when executed will do the appropriate
operations.

\begin{minted}{felix}
fun render_prod 
  (lib:gramlib_t,v:varray[ntdef_t]) 
  (p:prod_t) 
: 1 -> recog_t =>
  match p with
  | Terminal (s,r) => { r }
  | Epsilon => { BaseChips::epsilon[Buffer] }
  | Seq ps => { BaseChips::pipeline_list (
      map (fun (p:prod_t) => #(render_prod (lib,v) p)) ps) }
  | Alt ps =>  { BaseChips::tryall_list (
      map (fun (p:prod_t) => #(render_prod (lib,v) p)) ps) }
  | Nonterminal nt => 
     { 
       var idx : size = find v nt;
       var pslot : &ntdef_t = -(v.stl_begin + idx); 
       var pchip : &recog_t = pslot . 1;
       return BaseChips::deref_first_read pchip;
     }
  endmatch
;
\end{minted}

Since a terminal is defined with a debugging string $s$ and
a recogniser $r$, we just return the recogniser in that case.

If we have a sequence, we return a pipeline of the chips corresponding
to the entries in the sequence: we make the chips by recursively
mapping the render function over the entries in the list.

If we have alternatives, we do the same mapping but combine the chips
using the \verb%tryall_list% combinator instead of a pipeline.

The hard case is the nonterminal. We cannot just looklup the nonterminal
and substitute its definition, because grammars can be recursive.

Every problem can be solved by adding yet another level
of indirection! So what we do if find the index position of the
definition of the nonterminal, calculate the address in the output
arrayu $v$ that where the definition will eventually be put,
and then use the magical \verb%deref_first_read% chip which will delegate
its actions to the chip at the end of the pointer, but will only
do so on demand, after its first data is read.

\subsection{The generator chip}
Since we have to combine coroutines inside a coroutine, not a function,
we will make a chip which does the job.

This chip reads a whole grammar, and writes the corresponding
recogniser.

First we find the transitive closure of the nonterminals
reachable from the designated start symbol, since our data is
a library of nonterminal definitions,
not all the components in the library may be required
for the specified start symbol.

We make an array to store the chips for each nonterminal
in the closure and initialise them to the \verb%epsilon% chip
to expand the \verb%varray% to the right size, and to assign
the names of the nonterminals into the array.

Now we run the \verb%render_prod% function for each nonterminal,
and execute the returned generator to produce the chip we want,
which we then store in the array.

Then we just write the chip associated with the start symbol,
that's our recogniser. Note that the varray storing the nonterminals
and their recogniser is not lost, since it is reachable from
the starting chip.

\begin{minted}{felix}
chip make_recogniser_from_grammar
  connector io
    pin inp: %<grammar_t
    pin out: %>recog_t
{

  while true do
    // read in the grammar
    var start, lib = read io.inp;

    // calculate the transitive closure of nonterminals
    // from the start symbol
    var cl = closure (start,lib);

    // allocate a varray with a slot for each nonterminal
    var n = cl.len;
    var v = varray[string * recog_t] n;

    // populate the varray with the terminal names and a dummy chip
    for nt in cl call // initialise array
      push_back (v,(nt,BaseChips::epsilon[Buffer]))
    ;

    // now assign the real recognisers to the array
    var index = 0uz;
    for nt in cl do
      match find lib nt with
      | None => assert false;
      | Some prod =>
        // get wrapped recogniser
        var xprod_closure = render_prod (lib, v) prod;

        // undo the wrappingt
        var entry = #xprod_closure;

        // address of the slot
        var pentry : &recog_t = (-(v.stl_begin+index)).1;

        // overwrite dummy value
        pentry <- entry;
      endmatch;
      ++index;
    done
    write (io.out, (v.(find v start).1));
  done
}
\end{minted}

NOTE: I have no idea how this can possibly work since the \verb%render_prod%
function actually returns a generator function, not a procedure. That generator
must fail if anything it does makes a service call. In particular \verb%pipeline_list%,
for example, spawns all the component chips after connecting them,
and spawn requires a service call. However the test case works! Why?
Felix isn't smart enough to do the double level of inlining to achieve
this is it??
 

\part{Appendices}
\chapter{Coroutine Semantics}
\label{Coroutine Semantics}
\section{Objects}
A coroutine system consists of the following types of objects:
\begin{description}
\item[Scheduler] A device to hold a set of active fibres and
select one to be current.
\item[Channels] An object to support synchronisation and data transfer.
\item[Fibres] A thread of control which can be suspended and resumed.
\item[Continuations] An object representing the future of a coroutine.
\end{description}

\subsection{Scheduler States}
A scheduler is in one of two states:
\begin{description}
\item[Current] The currently running scheduler
\item[Suspended] A scheduler for which the Running fibre is
executing another scheduler.
\end{description}

\subsection{Fibre States}
Each fibre is in one of these states:
\begin{description}
\item[Running] Exactly one fibre per scheduler is always running.
\item[Active] Fibes which are ready to run but not running on a particular scheduler.
\item[Hungry] Fibres suspended waiting for input on a channel.
\item[Blocked] Fibres suspended waiting to perform output on a channel.
\end{description}

\subsection{Channel States}
Each channel is in one of these states:
\begin{description}
\item[Empty] There are no fibres associated with the channel.
\item[Hungry] A set of hungry fibres are waiting for input on the channel.
\item[Blocked] A set of blocked fibres are waiting to perform output on the channel.
\end{description}


\section{Abstract State}
\subsection{State Data by Sets}
A fibration system consists of 
\begin{enumerate}
\item A set of fibres $\mathcal F$
\item A set of channels $\mathcal C$
\item An integer $k$
\item An indexed set of schedulers $\mathcal S= \{s_i\}{\rm\ for\ }i=1 {\rm\ to\ }k$  
\end{enumerate}
and the following relations:
\begin{enumerate}
\item for each $i=1 {\rm\ to\ }k$ a pair $(R_i, \mathcal A_i)$ where $R_i$ is a fibre
and $\mathcal A_i$ is a set of fibres, these fibres being associated with
scheduler $s_i$, $R_i$ is the currently Running fibre of the scheduler,
and $\mathcal A_i$ is the set of Active fibres;
\item for each channel $c$ a set $\mathcal H_c$ of Hungry fibres
and a set $\mathcal B_c$ of Blocked fibres, such that one of these sets
is empty, if both sets are empty, the channel is said to be Empty,
otherwise it is said to be Hungry or Blocked depending on whether
the Hungry or Blocked set is nonempty;

\item A reachability relation to be described below
\end{enumerate}
with the requirement that each fibre is in precisely one of the sets $\{R_i\}$,
$A_i$, $H_c$ or $B_c$.

We define the relation 
\begin{align}
\mathrel H &= \{(f,c) \mid f \in \mathrel H_c\}&\rm Hunger\\
\mathrel B &= \{(f,c) \mid f \in \mathrel B_c\}&\rm Blockage\\
\mathcal F_{\mathcal H} &= \{f \mid \exists c . (f,c) \in \mathcal H\}&\rm Hungry\ Fibres\\
\mathcal F_{\mathcal B} &= \{f \mid \exists c . (f,c) \in \mathcal B\}&\rm Blocked\ Fibres\\
\mathcal C_{\mathcal H} &= \{ c \mid \exists f . (f,c) \in \mathcal H\}&\rm Hungry\ Channels\\
\mathcal C_{\mathcal B} &= \{ c \mid \exists f . (f,c) \in \mathcal B\}&\rm Blocked\ Channels\\
\mathcal E &= \{c \mid | \mathcal H_c = \mathcal B_c = \emptyset \}&\rm Empty\ Channels
\end{align}

\subsection{State Data by ML}
Using an ML like description may make the state data easier
to visualise.

\begin{minted}{felix}
scheduler =
  Run: fibre | NULL, 
  Active: Set[fibre]

channel = 
  | Empty 
  | Hungry: NonemptySet[fibre]
  | Blocked: NonemptySet[fibre]

fibre = (current: continuation)

continuation = 
  caller: continuation | NULL,
  PC: codeaddress,
  local: data
\end{minted}

\section{Operations}

\subsection{Spawn} 
The spawn operation takes as an argument a unit procedure and makes
a closure thereof the initial continuation
of a new fibre.  Of the pair consisting of the currently running
fibre (the spawner) and the new fibre (the spawnee) one will have Active
state and the other will be Running. It is not specified which
of the pair is Running.

\begin{equation}
{\mathcal F} \leftarrow {\mathcal F} \cup \{f\}
\end{equation}

where f is a fresh fibre and

\begin{equation}
R_k,{\mathcal A_k} \leftarrow
\begin{cases}
R_k,{\mathcal A_k} \cup \{f\} \\
f,{\mathcal A_k} \cup \{R_s\} \\
\end{cases}
\end{equation}

where the choice between the two cases is indeterminate.

\subsection{Run} 
The run operation is a subroutine. It increments $k$ and creates
a new scheduler $s_k$. The scheduler $s_{k-1}$ is Suspended. 

\begin{equation}
k \leftarrow k + 1
\end{equation}


It then takes as an argument a unit procedure and makes
a closure thereof the initial continuation
of a new fibre $f$ and makes that the running fibre $R_k$ of
the new current scheduler. The set of active fibres $A_k$
is set to $\emptyset$. 

 
\begin{equation}
{\mathcal F} \leftarrow {\mathcal F} \cup \{f\}
\end{equation}

where f is a fresh fibre and

\begin{equation}
R_k,\mathcal A_k \leftarrow
f,\emptyset
\end{equation}

The scheduler is then run as a subroutine. It returns when there
is no running fibre, which implies also there are no active
fibres left. $k$ is then decremented, scheduler $s_k$ again becomes Current, 
and the the
current continuation of its running fibre resumes.
\begin{equation}
k \leftarrow k - 1
\end{equation}

\subsection{Create channel}
A function which creates a channel.

\begin{align}
{\mathcal C} \leftarrow {\mathcal C} \cup \{c\}\\
{\mathcal E} \leftarrow {\mathcal E} \cup \{c\}
\end{align}
where c is a fresh channel.

\subsection{Read}
The read operation from fibre $r$ takes as an argument a channel $c$.

\begin{enumerate}
\item If the channel is Empty, the Running fibre performing the read
changes state to Hungry, the channel changes state to Hungry,
and the fibre is associated with the channel.
\begin{align}
{\mathcal H}&\leftarrow {\mathcal H} \cup \{(r,c)\}\\
{\mathcal E} &\leftarrow {\mathcal E} \setminus \{c\}
\end{align}

If there are no active fibres, the program terminates,
otherwise the scheduler selects an Active fibre and
changes its state to Running.  It is not specified which active 
fibre is chosen.

\begin{equation}
R_k,{\mathcal A_k} \leftarrow
\begin{cases}
\epsilon,{\mathcal A_k}& {\rm if\ } A_k=\emptyset \\
a,{\mathcal A_k} \setminus \{a\} & {\rm some\ } a\in A
\end{cases}
\end{equation}


\item If the channel is Hungry, the Running fibre changes state
to Hungry, and the fibre is associated with the channel.

\begin{align}
{\mathcal H}&\leftarrow {\mathcal H} \cup \{(r,c)\}\\
\end{align}

If there are no active fibres, the program terminates,
otherwise the scheduler selects an Active fibre and
changes its state to Running.  It is not specified which active 
fibre is chosen.

\begin{equation}
R_k,{\mathcal A_k} \leftarrow
\begin{cases}
\epsilon,{\mathcal A_k}& {\rm if} A_k=\emptyset \\
a,{\mathcal A_k} \setminus \{a\} & {\rm some\ } a\in A_k
\end{cases}
\end{equation}


\item If the channel is Blocked, one of the associated Blocked fibres $w$
is selected, and dissociated from the channel. 

\begin{equation}
{\mathcal B} \leftarrow {\mathcal B}\setminus (w,c)\\ 
\end{equation}

Of these two
fibres, one is changed to state Active and the other to Running.
It is not specified which fibre is chosen to be Running.

\begin{equation}
R_k,{\mathcal A_k} \leftarrow
\begin{cases}
R_k,{\mathcal A_k} \cup \{w\} \\
w,{\mathcal A_k} \cup \{R\} \\
\end{cases}
\end{equation}

The value supplied to the write operation of the Blocked
fibre will be pass to the Hungry fibre when it transitions
to Running state.


\end{enumerate}



\subsection{Write}
The write operation performed by fibre $w$ takes two arguments, a channel and a value
to be written.

\begin{enumerate}
\item If the channel is Empty, the Running fibre performing the write
changes state to Blocked, the channel changes state to Blocked,
and the fibre is associated with the channel.
\begin{align}
{\mathcal B}&\leftarrow {\mathcal B} \cup \{(w,c)\}\\
{\mathcal E} &\leftarrow {\mathcal E} \setminus \{c\}
\end{align}


If there are no active fibres, the program terminates,
otherwise the scheduler selects an Active fibre and
changes its state to Running.  It is not specified which active 
fibre is chosen.

\begin{equation}
R_k,{\mathcal A_k} \leftarrow
\begin{cases}
\epsilon,{\mathcal A_k}& {\rm if\ } A_k=\emptyset \\
a,{\mathcal A_k} \setminus \{a\} & {\rm some\ } a\in A
\end{cases}
\end{equation}


\item If the channel is Blocked, the Running fibre changes state
to Blocked, and the fibre is associated with the channel.

\begin{align}
{\mathcal B}&\leftarrow {\mathcal B} \cup \{(w,c)\}\\
\end{align}


If there are no active fibres, the program terminates,
otherwise the scheduler selects an Active fibre and
changes its state to Running.  It is not specified which active 
fibre is chosen.

\begin{equation}
R_k,{\mathcal A_k} \leftarrow
\begin{cases}
\epsilon,{\mathcal A_k}& {\rm if\ } A_k=\emptyset \\
a,{\mathcal A_k} \setminus \{a\} & {\rm some\ } a\in A
\end{cases}
\end{equation}


\item If the channel is Hungry, one of the associated Hungry fibres $r$
is selected, and dissociated from the channel.

\begin{equation}
{\mathcal H} \leftarrow {\mathcal H}\setminus (r,c)\\ 
\end{equation}


Of these two
fibres, one is changed to state Active and the other to Running.
It is not specified which fibre is chosen to be Running.

\begin{equation}
R_k,{\mathcal A_k} \leftarrow
\begin{cases}
R_k,{\mathcal A_k} \cup \{r\} \\
r,{\mathcal A_k} \cup \{R\} \\
\end{cases}
\end{equation}


The value supplied by the write operation of the Blocked
fibre will be pass to the Hungry fibre when it transitions
to Running state.
\end{enumerate}

\subsection{Reachability}
The Running, and, each Active fibre and its associated call chain of 
continuations are deemed to be Reachable.

If a channel is known to reachable fibre, it is also reachable.
A channel may be known because its address is stored in the local
data of a continuation of a fibre, or, it is reachable via some object
which can be reached from local data. The exact rules are 
programming language dependent.

Each fibre associated with a reachable channel is reachable.

The transitive closure of the reachability relation consists
of a closed, finite, collection or channels and fibres which
are reachable.

Unreachable fibres and channels are automtically garbage
collected.

\subsection{Elimination}
Fibres and channels are eliminated when they are 
no longer reachable.

A fibre may become unreachable in three ways.

\subsubsection{Suicide}
A fibre for which the initial continuation returns is said to be
dead, and  becomes unreachable. If there are no longer any Active fibres,
the program returns, otherwise the scheduler picks
one Active fibre and changes its state to Running.

\subsubsection{Starvation}
A fibre in the Hungry state becomes unreachable when the
channel on which it is waiting becomes unreachable.

\subsubsection{Blockage}
A fibre in the Blocked state becomes unreachable 
when the channel on which it is waiting becomes unreachable.

\section{LiveLock}
If a fibre is Hungry (or Blocked) on a reachable channel
but no future Running fibre will write (or read) that
channel, the fibre is said to be livelocked. The fibre
will never proceed but it cannot be removed from
the system because it is reachable via the channel.

A livelock is considered to transition to a deadlock
if the channel becomes unreachable, in which case
the fibre will becomes unreachable and is said to
die through Starvation (or Blockage),
disolving the deadlock. In other words, fibres cannot deadlock.


\section{Fibre Structure}
Each fibre consists of a single current continuation.
Each continuation may have an associated continuation
known as its caller. The initial continuation of a freshly
spawned fibre has no caller.

The closure of the caller relation leads to a linear
sequence of continuations starting with the current
continuation and ending with the initial continuation
of a freshly spawned fibre.

The main program consists of an initially Running
fibre with a specified initial continuation.

Continuations have the usual operations of a procedure.
They may return, call another procedure, spawn new
fibres, create channels, and read and write channels,
as well as the other usual operations of a procedure
in a general purpose programming language.

A continuation is reachable if it is the current
continuation of a reachable fibre, or the caller
of a reachable continuation.

A continuation is formed by calling a procedure,
which causes a data frame to be constructed which
contains the return address of the caller,
parameters and local variables of the procedure,
and a program counter containing the current
locus of control (code address) within the procedure.
The program counter is initially set to the specified
entry point of the procedure.

A coroutine is a procedure which directly or indirectly
performs channel I/O. Coroutines may be called by 
other coroutines, but not by procedures or functions.
Instead, a coroutine may be spawned by a procedure,
or run by a procedure or function. This creates a
fibre which hosts the created continuation.

Note: the set of fibres and channels created directly
or indirectly by a run subroutine called inside
a function should be isolated from all other fibres
and channels to ensure the function has no side-effects.



\section{Continuation Structure}
\subsection{Continuation Data}
A continuation has associated with it the following
data:

\begin{description}
\item[caller] Another continuation of the same fibre which is
suspended until this continuation returns.
\item[data frame] Sometimes called the stack frame, contains
local variables the continuation may access.
\item[program counter] A location in the program code representing
the current point of this continuations execution or suspension
\end{description}

\subsection{Continuation operations}
The current continuation of a fibre executes a wide range of
operations including channel I/O, spawning new fibres,
calling a procedure, and returning.

\begin{description}
\item[call] Calling a procedure creates a new continuation
with its program counter set at the procedure entry point,
and a fresh data frame. The new continuation becomes the
current continuation, the current continuation suspends.
The new continuations caller field is set to the caller.
The current continuation program counter is set
to the pointer after the call instruction.

The effect is push an entry onto the fibres continuation chain.

\item[return] Returning from the current continuation causes
the owning fibres current continuation to be set to the
current continuations caller, if one exists, or the 
fibre to be marked Dead if there is no caller. Execution
of the suspended caller continues at its program counter.

The effect is to pop an entry off the fibre's continuation chain.

\item[read/write] Channel I/O suspends the current continuation
of a fibre until a matching operation from another fibre
synchronises with it. A read is matched by a write, and a write
is matched by a read.
\end{description}

By the rules of state change, channel I/O should be viewed
as performing a peer to peer neutral exchange of control:
the current fibre becomes suspended without losing its position
and hands control to another fibre. Later, control is handed
back and the fibre continues.

Coroutine based systems, therefore, operate by repeated exchanges
of control accompanied by data transfers in a direction independent
of the control flow, which sets coroutines aside from functions.

\section{Events}
Each state transfer of the fibration system may be considered
an event. However the key events are
\begin{itemize}
\item spawning
\item suicide
\item entry to a read operation
\item return from a read operation
\item entry to a write operation
\item return from a write operation
\end{itemize}

I/O synchronisation consists of suspension on entry
to a read or write operation, and simultaneously release
of suspension, or resumption, on matching write or read.

I/O suspension occurs when a fibre becomes Hungry or Blocked,
and resumption when it becomes Running or Active.

Fibrated systems are characterised by a simple rule: events are
totally ordered. The order may not be determinate. 

\section{Control Type}
The control type of a coroutine is defined as follows.
We assume the coroutine is spawned as a fibre, and each
and every read request is satisfied by a random value of
the legal input type. Write requests are also satisfied.
We cojoin entry and return from read into a single read
event, and entry and return from write into a single
write event, since we are only interested in the behaviour
of the fibre.

The sequence of all possible events which the fibre
may exhibit is the coroutines control type. Note, the
control type is a property of the coroutine (procedure).

\section{Encoding Control Types}
In general, the control type of a coroutine can be quite
complex. However for special cases, a simple encoding
can be given.

\subsection{One shots}
A one-shot coutine is one that exhibits a bounded number
of events before suiciding. The three most common one
shots are:

\begin{description}
\item[Value: type W] A coroutine which writes a single value to
a channel and then exits.
\item[Result: type R] A coroutine which reads a single value to
from channel and then exits.
\item[Function: type RW] A couroutine which reads one value
from a channel, calculates an answer, writes that
down a channel and then exits.
\end{description}

\subsection{Continuous devices}
A continuous coroutine is one which does not exit.
It can therefore terminate only by starvation or blockage.
The three most common kinds of such devices are
\begin{description}
\item[Source: type W+] Writes a continuous stream of values
to a channel.
\item[Sink: type R+] Reads a continuous stream of values
from a channel.
\item[Transducer] Reads and writes.
\end{description}

Because the sequence of events is a stream, we may use
convenient notations to describe control types.
If possible, a regular expression will be used.
Sometimes, a grammar will be required. In other cases
there is no simple notation for the behaviour of a coroutine.

We will use postfix \verb%+% for repetition.
 
\subsection{Transducer Types}
A transducer which read a value, write a value, then loops
back and repeats is called a {\em functional transducer},
it may be given the type (RW)+.

In a functional language, a partial function has no natural
encoding. There are two common solutions. The first is to
return an option type, say Some v, if there is a result,
or None if there is not. This solution involves modifying
the codomain. The other solution is to restrict the domain so
that the subroutine is a function.

Coroutines, however, represent partial functions naturally.
If a value is read for which there is no result, none is written!
The type of a {\em partial function transducer} is therefore
given by ((R+)W)+, in other words multiple reads may occur
for each write. Note that two writes may not occur in succession.

This type may also be applied to many other coroutines,
for example the list filter higher order function.

\subsection{Duality}
Coroutines are dual to functions. The core difference is that
they operate in time not space. Thus, in the dual space
a spatial product type becomes a temporal sequence.

Coroutines are ideal for processing streams. Whereas
function code cannot construct streams without laziness,
and cannot deconstruct them without eagerness, coroutines
are neither eager nor lazy.

One may view an eager functional application as driving a
value into a function to get a result, and a lazy application
as pulling a value into a function. Pushing value implies
eagerly evaluating it, pulling implies the value is calculated
on demand.

Coroutine simultaneously push and pull values across channels
and so eliminate the evaluation model dichotomy that plagues
functional programming. This coherence does not come for
free: it is replaced by indeterminate event ordering.

\section{Composition}
By far the biggest advantage of coroutine modelling is the 
ultimate flexibility of composition. Coroutines provide
far better modularity and reusability than functions,
but this comes at the price of complexity. You will observe
considerably more housekeeping is required to compose
coroutines than procedures or functions, because, simply,
there are more way to compose them.

A collection of coroutines can be regarded as black boxes
resembling chips on a circuit board, with the wires
connecting pins representing channels. So instead of using
variables and binding constructions, we can construct more
or less arbitrary networks.

\subsection{Pipelines}
The simplest kind of composition is the pipeline. It is a sequence
of transduces wired together with the output of one transducer
connected by a channel to the input of the next.

If the pipeline consists entirely of transducers is is an open
pipeline. If there is a source at one end and a sink at the other
it is a closed pipeline. Partially open pipelines can also exist.

The composition of two transducers has a type dependent on
the left and right transducer types. 

With a functional transducer, you would expect the composition
of (R1W1)+ with (R2W2)+ to be (R1W2)+ but this is not the case!

Consider, the left transducer performs R1, then W1, then right
performs R2. At this point it is not determinate whether left
or right proceeds. If left proceeds, we have R1 again, then W1.
then right proceeds and performs W2 before coming back to read R2,
and what happens next is again indeterminate. The sequence is
therefore R1, W1/R2, R1, W1/R2 which shows R1 can be read twice
before W2 is observed. We have written w/r here to indicate synchronised
events which are abstracted away when describing the observable
behaviour of the composite.

Clearly, (R1?R1W2?W2)+ contains the set of possible event sequences,
but then (R1+R2+)+ contains it, and therefore the set of possible
event sequences as well. So we should seek the most precise, or
{\em principal} type of the composite.

We can calculate the type from the operational semantics.
At any point in time, the system must be in one of a finite
number of states. Where we have indeterminacy, the transitions
out of a given state are not fully specified. The result is
clearly a non-deterministic finite state automaton.

We must observe, such an automaton corresponds to (one or more) 
larger deterministic finite state automata. This is an important
result because it has practical implications: it means we can
pick a DFA and use it to optimise away abstracted synchronisation
points. In other words, we build a fast model of the system
by inlining and using shared variables instead of channels,
and then eliminate the variables by functional composition.

This is the primary reason we insist on indeterminate behaviour:
it allows composition to be subject to a reduction calculus.

\section{Felix Implementation}
The following functions and procedures are provided in Felix:

\begin{minted}{felix}
spawn_fthread: (1 -> 0) -> 0;
run: (1 -> 0) -> 0;
mk_ioschannel_pair[T]: 1 -> ischannel[T] * oschannel[T];
read[T]: ischannel[T] -> T
write[T]: oschannel[T] * T -> 0
\end{minted}

In the abstract, channels are bidirectional and untyped.
However we will restrict our attention to channels
typed to support either read (ischannel) or write (oschannel)
of a value of a fixed data type.

The following shorthand types are available:

\begin{minted}{felix}
%<T    ischannel[T]
%>T    oschannel[T]
\end{minted}

More advanced typing exploiting channel capabilities are
discussed later.

Simple example program:

\begin{minted}{felix}
proc demo () {
  var inp, out = mk_ioschannel_pair[int]();

  proc source () {
    for i in 1..10 perform write (out,i);
  }

  proc sink () {
    while true do
      var j = read inp;
      println$ j;
    done
  }

  spawn_fthread source;
  spawn_fthread sink;
}
demo();
\end{minted}

In this program, we create a channel with an input and
output end typed to transfer an int. The source coroutine
writes the integers from 1 through to 10 inclusive to
the write end of the channel, the sink coroutine
reads integers from the channel and prints them.

The main fibre calls the demo procedure which launches
two fibres with initial continuations the closures of
the source and sink procedures.

When demo returns, the main fibre's current continuation
no longer knows the channel, so the channel is not reachable
from the main fibre. 

The source coroutine returns after sending 10 integers to
the sink via the channel.  When a fibre no longer has
a current continuation, returning to the non-existent
caller causes the fibre to no longer have a legal
state. This is known as suicide.

After the sink has read the 
last value, it becomes permanently Hungry. The sink 
procedure dies by starvation.

All fibres which die do so either by suicide, starvation,
or blockage. Dead fibres will be reaped by the garbage
collector provided they're unreachable. It is important
for the creator of fibres and their connecting channels
to forget the channels to ensure this occurs.

Unlike typical pre-emptive threading systems, deadlock
is not an error. However a lock up which should lead to
reaping of fibres but which fails to do so because
they remain reachable is univerally an error. This is
known as a livelock: it leads to zombie fibres.

This usually occurs because some other fibre is statically
capable of resolving the lockup, but does not do so 
dynamically. To prevent livelocks, variables holding
channel values to which no I/O will occur dynamically
should also go out of scope.

\listoflistings
\indexprologue{Index of code names}
\printindex[codeindex] 
\printindex
\end{document}
